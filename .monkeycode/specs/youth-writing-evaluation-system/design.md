# é’å°‘å¹´å†™ä½œè´¨é‡è¯„æµ‹ç³»ç»ŸæŠ€æœ¯è®¾è®¡

Feature Name: youth-writing-evaluation-system
Updated: 2026-02-06
Version: 2.0

## 1. ç³»ç»Ÿæ¦‚è¿°

æœ¬ç³»ç»Ÿæ˜¯ä¸€ä¸ªé¢å‘å°å­¦é˜¶æ®µé’å°‘å¹´çš„å†™ä½œè´¨é‡æ™ºèƒ½è¯„æµ‹å¹³å°ï¼Œé‡‡ç”¨å‰åç«¯åˆ†ç¦»æ¶æ„ã€‚åç«¯åŸºäº FastAPI æ„å»ºï¼Œæä¾› LLM æ¨¡å‹æ— å…³çš„è¯„åˆ†å¼•æ“ï¼›å‰ç«¯åŸºäº Next.js + React + shadcn/ui æ„å»ºï¼Œæä¾›ç¾è§‚æ˜“ç”¨çš„ç”¨æˆ·ç•Œé¢ã€‚ç³»ç»Ÿæ”¯æŒå¤šæ¨¡å‹æœåŠ¡å•†æ¥å…¥ï¼Œç”¨æˆ·å¯çµæ´»é…ç½® OpenAIã€Claudeã€Geminiã€ç™¾åº¦æ–‡å¿ƒã€é˜¿é‡Œé€šä¹‰ã€æ™ºè°±æ¸…è¨€ç­‰å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œä½œæ–‡è¯„åˆ†ä¸ç‚¹è¯„ã€‚

## 2. ç³»ç»Ÿæ¶æ„

### 2.1 æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph å‰ç«¯å±‚
        UI[Next.js + React å‰ç«¯]
        Shadcn[shadcn/ui ç»„ä»¶åº“]
        Chart[å›¾è¡¨å¯è§†åŒ–]
        Upload[æ–‡ä»¶ä¸Šä¼ ç»„ä»¶]
    end

    subgraph åº”ç”¨å±‚
        API[FastAPI åç«¯æœåŠ¡]
        Auth[è®¤è¯æœåŠ¡]
        Score[è¯„åˆ†å¼•æ“]
        History[å†å²ç®¡ç†]
        Example[èŒƒæ–‡æœåŠ¡]
    end

    subgraph æ¨¡å‹æŠ½è±¡å±‚
        LLM[LLM Provider æ¥å£]
        
        subgraph æ¨¡å‹æœåŠ¡å•†
            OpenAI[OpenAI GPT-4]
            Claude[Anthropic Claude]
            Gemini[Google Gemini]
            Baidu[ç™¾åº¦æ–‡å¿ƒ]
            AZure[é˜¿é‡Œäº‘é€šä¹‰]
            ZhiPu[æ™ºè°±æ¸…è¨€]
            Custom[è‡ªå®šä¹‰æ¨¡å‹]
        end
    end

    subgraph æ•°æ®å±‚
        PG[(PostgreSQL æ•°æ®åº“)]
        Redis[(Redis ç¼“å­˜)]
        MinIO[(å¯¹è±¡å­˜å‚¨)]
    end

    UI --> API
    API --> Auth
    API --> Score
    API --> History
    API --> Example
    API --> LLM
    LLM --> OpenAI
    LLM --> Claude
    LLM --> Gemini
    LLM --> Baidu
    LLM --> AZure
    LLM --> ZhiPu
    LLM --> Custom
    API --> PG
    API --> Redis
    API --> MinIO
```

### 2.2 æŠ€æœ¯æ ˆé€‰å‹

| å±‚çº§ | æŠ€æœ¯é€‰å‹ | é€‰å‹ç†ç”± |
|------|----------|----------|
| å‰ç«¯æ¡†æ¶ | Next.js 14 + React 18 | App Router æ”¯æŒã€SSR/SSGã€ä¸°å¯Œç”Ÿæ€ |
| UIç»„ä»¶åº“ | shadcn/ui + Tailwind CSS | ç°ä»£åŒ–è®¾è®¡ã€ä¸»é¢˜å®šåˆ¶çµæ´»ã€ä»£ç æ‰€æœ‰æƒ |
| å›¾è¡¨åº“ | Recharts | React åŸç”Ÿã€å“åº”å¼ã€é«˜åº¦å¯å®šåˆ¶ |
| HTTPå®¢æˆ·ç«¯ | TanStack Query + Axios | çŠ¶æ€ç®¡ç†ã€è¯·æ±‚ç¼“å­˜ã€é”™è¯¯é‡è¯• |
| åç«¯æ¡†æ¶ | FastAPI + Python 3.11+ | é«˜æ€§èƒ½ã€è‡ªåŠ¨æ–‡æ¡£ã€ç±»å‹æç¤ºå®Œå–„ |
| ORM | SQLAlchemy 2.0 | æˆç†Ÿç¨³å®šã€çµæ´»æŸ¥è¯¢ã€è¿ç§»å·¥å…·å®Œå–„ |
| æ•°æ®åº“ | PostgreSQL 15+ | åŠŸèƒ½å¼ºå¤§ã€JSONæ”¯æŒã€æ•°æ®å®Œæ•´æ€§ |
| ç¼“å­˜ | Redis 7.x | é«˜æ€§èƒ½ã€ä¼šè¯å­˜å‚¨ã€APIé™æµ |
| å¯¹è±¡å­˜å‚¨ | MinIO / S3 | å…¼å®¹S3åè®®ã€å›¾ç‰‡å­˜å‚¨ã€æ‰©å±•æ–¹ä¾¿ |
| ä»»åŠ¡é˜Ÿåˆ— | Celery + Redis | å¼‚æ­¥ä»»åŠ¡ã€è¯„åˆ†æŠ¥å‘Šç”Ÿæˆã€OCRå¤„ç† |

## 3. å‰ç«¯è®¾è®¡ä¸å®ç°

### 3.1 é¡µé¢ç»“æ„

```mermaid
graph TB
    Home[é¦–é¡µ / ä»ªè¡¨ç›˜]
    Eval[ä½œæ–‡è¯„æµ‹é¡µ]
    History[å†å²è®°å½•é¡µ]
    Examples[èŒƒæ–‡åº“é¡µ]
    Settings[è®¾ç½®é¡µ]
    Profile[ä¸ªäººä¸­å¿ƒ]

    Home --> Eval
    Home --> History
    Home --> Examples
    Home --> Settings
    Home --> Profile
    Eval --> History
```

### 3.2 æ ¸å¿ƒé¡µé¢è®¾è®¡

#### 3.2.1 é¦–é¡µ / ä»ªè¡¨ç›˜

**é¡µé¢åŠŸèƒ½ï¼š** å±•ç¤ºç”¨æˆ·æ¦‚è§ˆã€å¿«é€Ÿå…¥å£ã€æ•°æ®ç»Ÿè®¡

**å¸ƒå±€ç»“æ„ï¼š**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Logo    å¯¼èˆªæ     æœç´¢æ¡†    ç”¨æˆ·å¤´åƒ                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  æ¬¢è¿å›æ¥ï¼Œå¼ å°æ˜ï¼                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚  ğŸ“Š æœ¬æœˆè¯„æµ‹: 12 ç¯‡    ğŸ“ˆ å¹³å‡åˆ†: 78.5    ğŸ† æœ€é«˜åˆ†: 92 â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  ğŸ“ å¿«é€Ÿè¯„æµ‹     â”‚  â”‚  ğŸ“ˆ è¿›æ­¥æ›²çº¿   â”‚                â”‚
â”‚  â”‚  ç«‹å³å¼€å§‹       â”‚  â”‚  æŸ¥çœ‹è¯¦æƒ…      â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                         â”‚
â”‚  æœ€è¿‘è¯„æµ‹                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ã€Šæˆ‘çš„å¦ˆå¦ˆã€‹â”‚ äº”å¹´çº§ â”‚ 85åˆ† â”‚ ä¼˜ç§€ â”‚ 2å°æ—¶å‰   â”‚    â”‚
â”‚  â”‚ ã€Šæ˜¥å¤©ã€‹    â”‚ ä¸‰å¹´çº§ â”‚ 72åˆ† â”‚ è‰¯å¥½ â”‚ æ˜¨å¤©     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ğŸ¯ è–„å¼±ç»´åº¦åˆ†æ                                   â”‚    â”‚
â”‚  â”‚  ç»“æ„ç»„ç»‡ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 65%                         â”‚    â”‚
â”‚  â”‚  ä¹¦å†™è§„èŒƒ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 90%                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å­—ä½“ä¸æ’ç‰ˆè®¾è®¡ï¼š**
- ä¸»æ ‡é¢˜ï¼šInter Boldï¼Œ28pxï¼ŒPrimary Color (#1E293B)
- å‰¯æ ‡é¢˜ï¼šInter Mediumï¼Œ18pxï¼ŒSecondary Color (#64748B)
- æ­£æ–‡ï¼šInter Regularï¼Œ16pxï¼ŒText Color (#334155)
- è¾…åŠ©æ–‡å­—ï¼šInter Regularï¼Œ14pxï¼ŒMuted Color (#94A3B8)
- æ•°æ®å¡ç‰‡æ•°å­—ï¼šInter Boldï¼Œ32pxï¼ŒAccent Color (#3B82F6)
- è¡Œé—´è·ï¼š1.6å€
- æ®µé—´è·ï¼š24px

**è‰²å½©ç³»ç»Ÿï¼ˆshadcn/ui ä¸»é¢˜ï¼‰ï¼š**
```typescript
const theme = {
  primary: {
    DEFAULT: "#3B82F6",
    foreground: "#FFFFFF",
  },
  secondary: {
    DEFAULT: "#F1F5F9",
    foreground: "#1E293B",
  },
  accent: {
    DEFAULT: "#8B5CF6",
    foreground: "#FFFFFF",
  },
  success: {
    DEFAULT: "#10B981",
    foreground: "#FFFFFF",
  },
  warning: {
    DEFAULT: "#F59E0B",
    foreground: "#FFFFFF",
  },
  destructive: {
    DEFAULT: "#EF4444",
    foreground: "#FFFFFF",
  },
  background: "#FAFAFA",
  foreground: "#1E293B",
}
```

#### 3.2.2 ä½œæ–‡è¯„æµ‹é¡µ

**é¡µé¢åŠŸèƒ½ï¼š** ä½œæ–‡è¾“å…¥ã€å¹´çº§é€‰æ‹©ã€æ¨¡å‹é…ç½®ã€è¯„æµ‹ç»“æœå±•ç¤º

**å¸ƒå±€ç»“æ„ï¼š**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â† è¿”å›                                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ“ ä½œæ–‡è¯„æµ‹                                              â”‚
â”‚                                                         â”‚
â”‚  å¹´çº§: [äº”å¹´çº§ â–¼]      å†™ä½œç±»å‹: [è‡ªåŠ¨è¯†åˆ« â–¼]             â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰                                     â”‚    â”‚
â”‚  â”‚  [____________________________________________] â”‚    â”‚
â”‚  â”‚                                                 â”‚    â”‚
â”‚  â”‚  ä½œæ–‡å†…å®¹                                         â”‚    â”‚
â”‚  â”‚  [____________________________________________] â”‚    â”‚
â”‚  â”‚  [____________________________________________] â”‚    â”‚
â”‚  â”‚  [____________________________________________] â”‚    â”‚
â”‚  â”‚  [____________________________________________] â”‚    â”‚
â”‚  â”‚                                                 â”‚    â”‚
â”‚  â”‚  ğŸ“ æ”¯æŒæ‹–æ‹½ä¸Šä¼  .txt .doc .docx .md .zip           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â”‚  âš™ï¸ è¯„åˆ†æ¨¡å‹é€‰æ‹©                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  â—‹ OpenAI GPT-4    â—‹ æ™ºè°±æ¸…è¨€    â—‹ é˜¿é‡Œé€šä¹‰     â”‚    â”‚
â”‚  â”‚  â—‹ Claude 3       â—‹ ç™¾åº¦æ–‡å¿ƒ    â—‹ è‡ªå®šä¹‰é…ç½®    â”‚    â”‚
â”‚  â”‚  [API Key: ________________________________]    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â”‚  [           å¼€å§‹è¯„æµ‹ (è“è‰²)            ]                â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¯„æµ‹ç»“æœ                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  â”Œâ”€ æ€»ä½“è¯„åˆ† â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚           85                                         â”‚   â”‚
â”‚  â”‚         ä¼˜ç§€                                         â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚         é›·è¾¾å›¾ï¼ˆå„ç»´åº¦å¾—åˆ†ï¼‰                   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚           å†…å®¹ä¸»é¢˜ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 28/30         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚           ç»“æ„ç»„ç»‡ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 18/20           â”‚  â”‚   â”‚
â”‚  â”‚  â”‚           è¯­è¨€è¡¨è¾¾ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 23/25          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚           ä¹¦å†™è§„èŒƒ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 14/15         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚           åˆ›æ„ç‰¹è‰² â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘ 6/10          â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                         â”‚
â”‚  ğŸ“‹ è¯¦ç»†è¯„åˆ†                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ âœ… å†…å®¹å……å®ï¼Œä¸»é¢˜æ˜ç¡®ï¼Œæƒ…æ„ŸçœŸæŒš                     â”‚    â”‚
â”‚  â”‚ âš ï¸  ç»“æ„ç•¥æ˜¾å•ä¸€ï¼Œå¯å¢åŠ ç»†èŠ‚æå†™                   â”‚    â”‚
â”‚  â”‚ âœ… è¯­è¨€æµç•…ï¼Œç”¨è¯å‡†ç¡®                               â”‚    â”‚
â”‚  â”‚ âœ… é”™åˆ«å­—è¾ƒå°‘ï¼Œæ ‡ç‚¹ä½¿ç”¨æ­£ç¡®                         â”‚    â”‚
â”‚  â”‚ ğŸ’¡ å¼€å¤´å¼•äººå…¥èƒœï¼Œå¯ç»§ç»­å‘æŒ¥æƒ³è±¡åŠ›                   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â”‚  ğŸ’¡ æ”¹è¿›å»ºè®®                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. ä¸°å¯Œäººç‰©æå†™ï¼ŒåŠ å…¥æ›´å¤šç»†èŠ‚å’ŒåŠ¨ä½œæå†™            â”‚    â”‚
â”‚  â”‚ 2. å°è¯•ä½¿ç”¨æ›´å¤šä¿®è¾æ‰‹æ³•ï¼Œå¦‚æ¯”å–»ã€æ‹Ÿäºº              â”‚    â”‚
â”‚  â”‚ 3. ç»“å°¾å¯ä»¥æ›´æœ‰æ·±æ„ï¼Œå›æ‰£ä¸»é¢˜                       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â”‚  ğŸ“– èŒƒæ–‡å¯¹æ¯”                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ã€Šæˆ‘çš„å¦ˆå¦ˆã€‹- ä¼˜ç§€èŒƒæ–‡å¯¹æ¯”                         â”‚    â”‚
â”‚  â”‚ å¯¹æ¯”åˆ†æ | åŸæ–‡ | èŒƒæ–‡ | å­¦ä¹ å»ºè®®                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 æ ¸å¿ƒç»„ä»¶è®¾è®¡

```mermaid
graph TB
    subgraph UIç»„ä»¶
        Button[Button æŒ‰é’®]
        Input[Input è¾“å…¥æ¡†]
        Select[Select é€‰æ‹©å™¨]
        Card[Card å¡ç‰‡]
        Dialog[Dialog å¯¹è¯æ¡†]
        Table[Table è¡¨æ ¼]
        Tabs[Tabs æ ‡ç­¾é¡µ]
    end

    subgraph ä¸šåŠ¡ç»„ä»¶
        EssayEditor[EssayEditor ä½œæ–‡ç¼–è¾‘å™¨]
        GradeSelector[GradeSelector å¹´çº§é€‰æ‹©å™¨]
        ModelSelector[ModelSelector æ¨¡å‹é€‰æ‹©å™¨]
    end

    subgraph è¯„åˆ†å±•ç¤ºç»„ä»¶
        ScoreCard[ScoreCard è¯„åˆ†å¡ç‰‡]
        RadarChart[RadarChart é›·è¾¾å›¾]
        ProgressBar[ProgressBar è¿›åº¦æ¡]
        SuggestionList[SuggestionList å»ºè®®åˆ—è¡¨]
        ExampleCompare[ExampleCompare èŒƒæ–‡å¯¹æ¯”]
    end

    subgraph å›¾è¡¨ç»„ä»¶
        TrendChart[TrendChart è¶‹åŠ¿å›¾]
        HistoryChart[HistoryChart å†å²å›¾]
    end

    EssayEditor --> Input
    EssayEditor --> Button
    GradeSelector --> Select
    ModelSelector --> Select
    ModelSelector --> Input
    ScoreCard --> Card
    RadarChart --> ProgressBar
```

#### 3.3.1 ä½œæ–‡ç¼–è¾‘å™¨ç»„ä»¶ (EssayEditor)

```tsx
// components/essay-editor.tsx
interface EssayEditorProps {
  grade: Grade;
  onGradeChange: (grade: Grade) => void;
  onSubmit: (essay: Essay) => Promise<void>;
}

export function EssayEditor({ grade, onGradeChange, onSubmit }: EssayEditorProps) {
  const [title, setTitle] = useState("");
  const [content, setContent] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  const fileInputRef = useRef<HTMLInputElement>(null);

  return (
    <Card className="w-full max-w-4xl mx-auto">
      <CardHeader>
        <CardTitle className="text-2xl font-bold">ğŸ“ ä½œæ–‡è¯„æµ‹</CardTitle>
      </CardHeader>
      <CardContent className="space-y-6">
        <div className="flex gap-4">
          <div className="w-1/3">
            <Label>å¹´çº§</Label>
            <GradeSelector value={grade} onChange={onGradeChange} />
          </div>
          <div className="w-2/3">
            <Label>æ ‡é¢˜ï¼ˆå¯é€‰ï¼‰</Label>
            <Input
              placeholder="è¯·è¾“å…¥ä½œæ–‡æ ‡é¢˜"
              value={title}
              onChange={(e) => setTitle(e.target.value)}
            />
          </div>
        </div>

        <div>
          <Label>ä½œæ–‡å†…å®¹</Label>
          <Textarea
            placeholder="è¯·è¾“å…¥æˆ–ç²˜è´´ä½œæ–‡å†…å®¹..."
            className="min-h-[300px] font-medium text-base leading-relaxed"
            value={content}
            onChange={(e) => setContent(e.target.value)}
          />
        </div>

        <div className="border-2 border-dashed border-gray-200 rounded-lg p-6 text-center">
          <Upload className="mx-auto h-12 w-12 text-gray-400" />
            <p className="mt-2 text-sm text-gray-600">
              æ”¯æŒæ‹–æ‹½ä¸Šä¼  .txt .doc .docx .md .zip
            </p>
            <input
              type="file"
              ref={fileInputRef}
              className="hidden"
              accept=".txt,.doc,.docx,.md,.zip"
              multiple={true}
              onChange={handleFileUpload}
            />
          <Button
            variant="outline"
            className="mt-4"
            onClick={() => fileInputRef.current?.click()}
          >
            é€‰æ‹©æ–‡ä»¶
          </Button>
        </div>

        <Button
          className="w-full h-12 text-lg"
          onClick={handleSubmit}
          disabled={isLoading || !content.trim()}
        >
          {isLoading ? (
            <>
              <Loader2 className="mr-2 h-4 w-4 animate-spin" />
              è¯„æµ‹ä¸­...
            </>
          ) : (
            "å¼€å§‹è¯„æµ‹"
          )}
        </Button>
      </CardContent>
    </Card>
  );
}
```

#### 3.3.2 è¯„åˆ†å±•ç¤ºå¡ç‰‡ç»„ä»¶ (ScoreCard)

```tsx
// components/score-card.tsx
interface ScoreCardProps {
  totalScore: number;
  grade: string;
  dimensionScores: DimensionScore[];
  onViewDetails: () => void;
}

export function ScoreCard({ totalScore, grade, dimensionScores, onViewDetails }: ScoreCardProps) {
  const getGradeColor = (score: number) => {
    if (score >= 85) return "text-green-500";
    if (score >= 70) return "text-blue-500";
    if (score >= 60) return "text-yellow-500";
    return "text-red-500";
  };

  const getGradeLabel = (score: number) => {
    if (score >= 85) return "ä¼˜ç§€";
    if (score >= 70) return "è‰¯å¥½";
    if (score >= 60) return "åˆæ ¼";
    return "å¾…æé«˜";
  };

  return (
    <Card className="bg-gradient-to-br from-blue-50 to-indigo-50">
      <CardContent className="pt-6">
        <div className="flex items-center justify-between">
          <div className="text-center">
            <p className="text-sm text-gray-500">æ€»åˆ†</p>
            <p className="text-7xl font-bold text-blue-600">{totalScore}</p>
            <p className={`text-2xl font-medium ${getGradeColor(totalScore)}`}>
              {getGradeLabel(totalScore)}
            </p>
          </div>

          <div className="flex-1 ml-8 space-y-3">
            {dimensionScores.map((dim) => (
              <div key={dim.name} className="space-y-1">
                <div className="flex justify-between text-sm">
                  <span className="font-medium">{dim.name}</span>
                  <span className="text-gray-500">
                    {dim.score}/{dim.maxScore}
                  </span>
                </div>
                <ProgressBar
                  value={dim.score}
                  max={dim.maxScore}
                  color={dim.color}
                />
              </div>
            ))}
          </div>
        </div>

        <Button onClick={onViewDetails} className="w-full mt-6">
          æŸ¥çœ‹è¯¦ç»†åˆ†æ
        </Button>
      </CardContent>
    </Card>
  );
}
```

#### 3.3.3 é›·è¾¾å›¾ç»„ä»¶ (RadarChart)

```tsx
// components/radar-chart.tsx
"use client";

import {
  Radar,
  RadarChart as RechartsRadarChart,
  PolarGrid,
  PolarAngleAxis,
  PolarRadiusAxis,
  ResponsiveContainer,
} from "recharts";

interface RadarChartProps {
  data: {
    subject: string;
    score: number;
    fullMark: number;
  }[];
}

export function RadarChart({ data }: RadarChartProps) {
  return (
    <ResponsiveContainer width="100%" height={300}>
      <RechartsRadarChart data={data}>
        <PolarGrid stroke="#E2E8F0" />
        <PolarAngleAxis
          dataKey="subject"
          tick={{ fill: "#64748B", fontSize: 12 }}
        />
        <PolarRadiusAxis
          angle={30}
          domain={[0, "auto"]}
          tick={{ fill: "#94A3B8", fontSize: 10 }}
        />
        <Radar
          name="å¾—åˆ†"
          dataKey="score"
          stroke="#3B82F6"
          fill="#3B82F6"
          fillOpacity={0.5}
        />
      </RechartsRadarChart>
    </ResponsiveContainer>
  );
}
```

### 3.4 shadcn/ui é…ç½®

```tsx
// components.json
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "default",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "app/globals.css",
    "baseColor": "slate",
    "cssVariables": true
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils"
  }
}
```

```tsx
// tailwind.config.ts
import { fontFamily } from "tailwindcss/defaultTheme";

export const theme = {
  extend: {
    fontFamily: {
      sans: ["Inter", ...fontFamily.sans],
      serif: ["Merriweather", ...fontFamily.serif],
      mono: ["JetBrains Mono", ...fontFamily.mono],
    },
    colors: {
      border: "hsl(var(--border))",
      input: "hsl(var(--input))",
      ring: "hsl(var(--ring))",
      background: "hsl(var(--background))",
      foreground: "hsl(var(--foreground))",
      primary: {
        DEFAULT: "hsl(var(--primary))",
        foreground: "hsl(var(--primary-foreground))",
      },
      secondary: {
        DEFAULT: "hsl(var(--secondary))",
        foreground: "hsl(var(--secondary-foreground))",
      },
      destructive: {
        DEFAULT: "hsl(var(--destructive))",
        foreground: "hsl(var(--destructive-foreground))",
      },
      muted: {
        DEFAULT: "hsl(var(--muted))",
        foreground: "hsl(var(--muted-foreground))",
      },
      accent: {
        DEFAULT: "hsl(var(--accent))",
        foreground: "hsl(var(--accent-foreground))",
      },
      popover: {
        DEFAULT: "hsl(var(--popover))",
        foreground: "hsl(var(--popover-foreground))",
      },
      card: {
        DEFAULT: "hsl(var(--card))",
        foreground: "hsl(var(--card-foreground))",
      },
    },
    borderRadius: {
      lg: "var(--radius)",
      md: "calc(var(--radius) - 2px)",
      sm: "calc(var(--radius) - 4px)",
    },
  },
};
```

## 4. åç«¯è®¾è®¡ä¸å®ç°

### 4.1 é¡¹ç›®ç»“æ„

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ essays.py       # ä½œæ–‡è¯„æµ‹æ¥å£
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ history.py      # å†å²è®°å½•æ¥å£
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ examples.py     # èŒƒæ–‡æ¥å£
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ models.py       # æ¨¡å‹é…ç½®æ¥å£
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ users.py       # ç”¨æˆ·æ¥å£
â”‚   â”‚   â”‚   â””â”€â”€ router.py           # è·¯ç”±é…ç½®
â”‚   â”‚   â”œâ”€â”€ deps.py                # ä¾èµ–æ³¨å…¥
â”‚   â”‚   â””â”€â”€ main.py                # åº”ç”¨å…¥å£
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ security.py            # å®‰å…¨è®¤è¯
â”‚   â”‚   â””â”€â”€ logging.py             # æ—¥å¿—é…ç½®
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py            # ç”¨æˆ·æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ essay.py           # ä½œæ–‡æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ evaluation.py      # è¯„æµ‹æ¨¡å‹
â”‚   â”‚   â”‚   â”œâ”€â”€ example.py         # èŒƒæ–‡æ¨¡å‹
â”‚   â”‚   â”‚   â””â”€â”€ model_config.py    # æ¨¡å‹é…ç½®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ database.py            # æ•°æ®åº“æ¨¡å‹
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ essay.py               # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â””â”€â”€ model_config.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py            # LLM Provider æŠ½è±¡åŸºç±»
â”‚   â”‚   â”‚   â”œâ”€â”€ openai.py          # OpenAI å®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ anthropic.py       # Claude å®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ google.py          # Gemini å®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ baidu.py           # ç™¾åº¦æ–‡å¿ƒå®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ aliyun.py          # é˜¿é‡Œé€šä¹‰å®ç°
â”‚   â”‚   â”‚   â”œâ”€â”€ zhipu.py           # æ™ºè°±æ¸…è¨€å®ç°
â”‚   â”‚   â”‚   â””â”€â”€ factory.py         # æ¨¡å‹å·¥å‚
â”‚   â”‚   â”œâ”€â”€ scoring/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ engine.py          # è¯„åˆ†å¼•æ“
â”‚   â”‚   â”‚   â”œâ”€â”€ parser.py          # ä½œæ–‡è§£æå™¨
â”‚   â”‚   â”‚   â””â”€â”€ formatter.py       # ç»“æœæ ¼å¼åŒ–
â”‚   â”‚   â”œâ”€â”€ essay/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py         # ä½œæ–‡æœåŠ¡
â”‚   â”‚   â”‚   â””â”€â”€ classifier.py      # ä½œæ–‡åˆ†ç±»å™¨
â”‚   â”‚   â”œâ”€â”€ history/
â”‚   â”‚   â”‚   â””â”€â”€ service.py         # å†å²è®°å½•æœåŠ¡
â”‚   â”‚   â””â”€â”€ example/
â”‚   â”‚       â””â”€â”€ service.py         # èŒƒæ–‡æœåŠ¡
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ text.py                 # æ–‡æœ¬å¤„ç†å·¥å…·
â”‚       â””â”€â”€ file.py                 # æ–‡ä»¶å¤„ç†å·¥å…·
â”‚
â”œâ”€â”€ migrations/
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â””â”€â”€ Dockerfile
```

### 4.2 LLM Provider æŠ½è±¡è®¾è®¡

```python
# app/services/llm/base.py
from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional
from pydantic import BaseModel


class LLMResponse(BaseModel):
    """LLM å“åº”æ¨¡å‹"""
    content: str
    usage: Optional[Dict[str, int]] = None
    model: str
    finish_reason: Optional[str] = None
    raw_response: Optional[Any] = None


class LLMProvider(ABC):
    """LLM æœåŠ¡å•†æŠ½è±¡åŸºç±»"""

    @property
    @abstractmethod
    def provider_name(self) -> str:
        """æœåŠ¡å•†åç§°"""
        pass

    @property
    @abstractmethod
    def supported_models(self) -> List[str]:
        """æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        pass

    @abstractmethod
    async def generate(
        self,
        prompt: str,
        model: Optional[str] = None,
        temperature: float = 0.3,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> LLMResponse:
        """ç”Ÿæˆå†…å®¹"""
        pass

    @abstractmethod
    def validate_api_key(self, api_key: str) -> bool:
        """éªŒè¯ API Key æ˜¯å¦æœ‰æ•ˆ"""
        pass

    @abstractmethod
    def to_config_dict(self, api_key: str) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºé…ç½®å­—å…¸"""
        pass


class EssayScoringTemplate:
    """ä½œæ–‡è¯„åˆ†æç¤ºè¯æ¨¡æ¿"""

    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å°å­¦è¯­æ–‡æ•™å¸ˆï¼Œä¸“é—¨è´Ÿè´£è¯„ä»·å°å­¦ç”Ÿçš„ä½œæ–‡ã€‚ä½ çš„è¯„ä»·åº”å½“ï¼š

1. **æ¸©å’Œé¼“åŠ±**ï¼šå§‹ç»ˆä»¥é¼“åŠ±ä¸ºä¸»ï¼Œé¿å…æ‰“å‡»å­¦ç”Ÿç§¯ææ€§
2. **å…·ä½“æ˜ç¡®**ï¼šæŒ‡å‡ºå…·ä½“ä¼˜ç‚¹å’Œéœ€è¦æ”¹è¿›çš„åœ°æ–¹
3. **é€‚é¾„è¯„ä»·**ï¼šæ ¹æ®å­¦ç”Ÿçš„å¹´çº§è°ƒæ•´è¯„ä»·æ ‡å‡†
4. **å»ºè®¾æ€§å»ºè®®**ï¼šæä¾›åˆ‡å®å¯è¡Œçš„æ”¹è¿›å»ºè®®

è¯·æŒ‰ç…§æˆ‘æä¾›çš„è¯„åˆ†ç»´åº¦å¯¹ä½œæ–‡è¿›è¡Œè¯„ä»·ã€‚
"""

    SCORING_DIMENSIONS = {
        "content_theme": {
            "name": "å†…å®¹ä¸»é¢˜",
            "description": "è¯„ä¼°ä¸»é¢˜æ˜¯å¦æ˜ç¡®ã€å†…å®¹æ˜¯å¦å……å®ã€æ€æƒ³æ˜¯å¦æœ‰æ·±åº¦",
            "weight": {"ä¸€å¹´çº§": 0.25, "äºŒå¹´çº§": 0.25, "ä¸‰å¹´çº§": 0.25, "å››å¹´çº§": 0.28, "äº”å¹´çº§": 0.30, "å…­å¹´çº§": 0.30}
        },
        "structure": {
            "name": "ç»“æ„ç»„ç»‡",
            "description": "è¯„ä¼°æ®µè½æ˜¯å¦æ¸…æ™°ã€é€»è¾‘æ˜¯å¦è¿è´¯ã€å¼€å¤´ç»“å°¾æ˜¯å¦ç²¾å½©",
            "weight": {"ä¸€å¹´çº§": 0.15, "äºŒå¹´çº§": 0.15, "ä¸‰å¹´çº§": 0.20, "å››å¹´çº§": 0.22, "äº”å¹´çº§": 0.22, "å…­å¹´çº§": 0.25}
        },
        "language": {
            "name": "è¯­è¨€è¡¨è¾¾",
            "description": "è¯„ä¼°ç”¨è¯æ˜¯å¦å‡†ç¡®ã€å¥å¼æ˜¯å¦ä¸°å¯Œã€è¡¨è¾¾æ˜¯å¦æµç•…",
            "weight": {"ä¸€å¹´çº§": 0.30, "äºŒå¹´çº§": 0.30, "ä¸‰å¹´çº§": 0.25, "å››å¹´çº§": 0.25, "äº”å¹´çº§": 0.23, "å…­å¹´çº§": 0.22}
        },
        "writing_norm": {
            "name": "ä¹¦å†™è§„èŒƒ",
            "description": "è¯„ä¼°é”™åˆ«å­—æ•°é‡ã€æ ‡ç‚¹ä½¿ç”¨ã€æ ¼å¼è§„èŒƒ",
            "weight": {"ä¸€å¹´çº§": 0.25, "äºŒå¹´çº§": 0.25, "ä¸‰å¹´çº§": 0.20, "å››å¹´çº§": 0.15, "äº”å¹´çº§": 0.15, "å…­å¹´çº§": 0.13}
        },
        "creativity": {
            "name": "åˆ›æ„ç‰¹è‰²",
            "description": "è¯„ä¼°æ˜¯å¦æœ‰ç‹¬ç‰¹è§†è§’ã€åˆ›æ–°è¡¨è¾¾ã€ä¸ªäººé£æ ¼",
            "weight": {"ä¸€å¹´çº§": 0.05, "äºŒå¹´çº§": 0.05, "ä¸‰å¹´çº§": 0.10, "å››å¹´çº§": 0.10, "äº”å¹´çº§": 0.10, "å…­å¹´çº§": 0.10}
        }
    }

    @classmethod
    def build_scoring_prompt(
        cls,
        essay_content: str,
        essay_title: Optional[str],
        grade: str,
        essay_type: str
    ) -> str:
        """æ„å»ºè¯„åˆ†æç¤ºè¯"""
        dimension_weights = cls.SCORING_DIMENSIONS
        weight = {
            dim: info["weight"][grade]
            for dim, info in dimension_weights.items()
        }

        prompt = f"""{cls.SYSTEM_PROMPT}

## ä½œæ–‡ä¿¡æ¯
- å¹´çº§ï¼š{grade}
- å†™ä½œç±»å‹ï¼š{essay_type}
- æ ‡é¢˜ï¼š{essay_title or 'æ— '}
- æ­£æ–‡ï¼š
---
{essay_content}
---

## è¯„åˆ†ç»´åº¦ä¸æƒé‡
è¯·å¯¹ä»¥ä¸‹äº”ä¸ªç»´åº¦è¿›è¡Œè¯„åˆ†ï¼ˆæ€»åˆ†100åˆ†ï¼‰ï¼š

### 1. å†…å®¹ä¸»é¢˜ï¼ˆæ»¡åˆ†30åˆ†ï¼Œæƒé‡{weight['content_theme']*100:.0f}%ï¼‰
è¯„ä¼°è¦ç‚¹ï¼š
- ä¸»é¢˜æ˜¯å¦æ˜ç¡®ã€çªå‡º
- å†…å®¹æ˜¯å¦å……å®ã€å…·ä½“
- æ€æƒ³æ˜¯å¦æœ‰æ·±åº¦ã€æ„Ÿæ‚Ÿæ˜¯å¦çœŸæŒš
å¾—åˆ†èŒƒå›´ï¼š0-30åˆ†

### 2. ç»“æ„ç»„ç»‡ï¼ˆæ»¡åˆ†20åˆ†ï¼Œæƒé‡{weight['structure']*100:.0f}%ï¼‰
è¯„ä¼°è¦ç‚¹ï¼š
- æ®µè½åˆ’åˆ†æ˜¯å¦æ¸…æ™°
- é€»è¾‘æ˜¯å¦è¿è´¯ã€æ¡ç†æ¸…æ¥š
- å¼€å¤´æ˜¯å¦å¸å¼•äººã€ç»“å°¾æ˜¯å¦ç²¾å½©
å¾—åˆ†èŒƒå›´ï¼š0-20åˆ†

### 3. è¯­è¨€è¡¨è¾¾ï¼ˆæ»¡åˆ†25åˆ†ï¼Œæƒé‡{weight['language']*100:.0f}%ï¼‰
è¯„ä¼°è¦ç‚¹ï¼š
- ç”¨è¯æ˜¯å¦å‡†ç¡®ã€ç”ŸåŠ¨
- å¥å¼æ˜¯å¦ä¸°å¯Œå¤šå˜
- è¡¨è¾¾æ˜¯å¦æµç•…ã€é€šé¡º
å¾—åˆ†èŒƒå›´ï¼š0-25åˆ†

### 4. ä¹¦å†™è§„èŒƒï¼ˆæ»¡åˆ†15åˆ†ï¼Œæƒé‡{weight['writing_norm']*100:.0f}%ï¼‰
è¯„ä¼°è¦ç‚¹ï¼š
- é”™åˆ«å­—æ•°é‡ï¼ˆæ¯2ä¸ªé”™åˆ«å­—æ‰£1åˆ†ï¼Œä¸Šé™æ‰£5åˆ†ï¼‰
- æ ‡ç‚¹ä½¿ç”¨æ˜¯å¦æ­£ç¡®
- æ ¼å¼æ˜¯å¦è§„èŒƒ
å¾—åˆ†èŒƒå›´ï¼š0-15åˆ†

### 5. åˆ›æ„ç‰¹è‰²ï¼ˆæ»¡åˆ†10åˆ†ï¼Œæƒé‡{weight['creativity']*100:.0f}%ï¼‰
è¯„ä¼°è¦ç‚¹ï¼š
- æ˜¯å¦æœ‰ç‹¬ç‰¹çš„è§‚å¯Ÿè§†è§’
- æ˜¯å¦æœ‰åˆ›æ–°çš„è¡¨è¾¾æ–¹å¼
- æ˜¯å¦å±•ç°å‡ºä¸ªäººé£æ ¼
å¾—åˆ†èŒƒå›´ï¼š0-10åˆ†

## è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºè¯„åˆ†ç»“æœï¼š

```json
{{
    "total_score": 85,
    "grade": "ä¼˜ç§€",
    "dimensions": {{
        "content_theme": {{
            "score": 28,
            "max_score": 30,
            "comment": "å†…å®¹å……å®ï¼Œä¸»é¢˜æ˜ç¡®..."
        }},
        "structure": {{
            "score": 18,
            "max_score": 20,
            "comment": "ç»“æ„æ¸…æ™°..."
        }},
        "language": {{
            "score": 22,
            "max_score": 25,
            "comment": "è¯­è¨€æµç•…..."
        }},
        "writing_norm": {{
            "score": 12,
            "max_score": 15,
            "comment": "é”™åˆ«å­—è¾ƒå°‘..."
        }},
        "creativity": {{
            "score": 5,
            "max_score": 10,
            "comment": "æœ‰ä¸€å®šåˆ›æ„..."
        }}
    }},
    "strengths": [
        "ä¸»é¢˜æ˜ç¡®ï¼Œæƒ…æ„ŸçœŸæŒš",
        "è¯­è¨€æµç•…ï¼Œç”¨è¯å‡†ç¡®"
    ],
    "weaknesses": [
        "ç»“æ„ç•¥æ˜¾å•ä¸€"
    ],
    "suggestions": [
        "å»ºè®®å¢åŠ æ›´å¤šç»†èŠ‚æå†™",
        "å¯ä»¥å°è¯•ä½¿ç”¨æ¯”å–»ã€æ‹Ÿäººç­‰ä¿®è¾æ‰‹æ³•"
    ],
    "essay_type_analysis": {{
        "identified_type": "è®°å™æ–‡",
        "type_match_score": 0.9,
        "type_specific_comments": "å…­è¦ç´ åŸºæœ¬å®Œæ•´ï¼Œäº‹ä»¶æå†™è¾ƒä¸ºç”ŸåŠ¨"
    }}
}}
```
"""
        return prompt
```

### 4.3 OpenAI Provider å®ç°

```python
# app/services/llm/openai.py
from typing import Any, Dict, List, Optional
from openai import AsyncOpenAI
from openai.types import Completion
from pydantic import BaseModel

from app.services.llm.base import LLMProvider, LLMResponse


class OpenAIProvider(LLMProvider):
    """OpenAI æœåŠ¡å•†å®ç°"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self._client: Optional[AsyncOpenAI] = None

    @property
    def provider_name(self) -> str:
        return "OpenAI"

    @property
    def supported_models(self) -> List[str]:
        return ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"]

    @property
    def client(self) -> AsyncOpenAI:
        if self._client is None:
            self._client = AsyncOpenAI(api_key=self.api_key)
        return self._client

    async def generate(
        self,
        prompt: str,
        model: str = "gpt-4-turbo",
        temperature: float = 0.3,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> LLMResponse:
        response = await self.client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°å­¦è¯­æ–‡æ•™å¸ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature,
            max_tokens=max_tokens,
            response_format={"type": "json_object"}
        )

        return LLMResponse(
            content=response.choices[0].message.content or "",
            usage={
                "prompt_tokens": response.usage.prompt_tokens,
                "completion_tokens": response.usage.completion_tokens,
                "total_tokens": response.usage.total_tokens
            },
            model=model,
            finish_reason=response.choices[0].finish_reason,
            raw_response=response
        )

    def validate_api_key(self, api_key: str) -> bool:
        try:
            client = AsyncOpenAI(api_key=api_key)
            # ç®€å•éªŒè¯ï¼šå°è¯•è°ƒç”¨ä¸€ä¸ªè½»é‡çº§è¯·æ±‚
            import asyncio
            # å®é™…éªŒè¯ä»£ç ...
            return True
        except Exception:
            return False

    def to_config_dict(self, api_key: str) -> Dict[str, Any]:
        return {
            "provider": "openai",
            "api_key": api_key,
            "models": self.supported_models
        }
```

### 4.4 Claude Provider å®ç°

```python
# app/services/llm/anthropic.py
from typing import Any, Dict, List, Optional
import anthropic
from anthropic import Anthropic

from app.services.llm.base import LLMProvider, LLMResponse


class AnthropicProvider(LLMProvider):
    """Anthropic Claude æœåŠ¡å•†å®ç°"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        self._client: Optional[Anthropic] = None

    @property
    def provider_name(self) -> str:
        return "Anthropic Claude"

    @property
    def supported_models(self) -> List[str]:
        return ["claude-3-5-sonnet-20241022", "claude-3-haiku-20240307"]

    @property
    def client(self) -> Anthropic:
        if self._client is None:
            self._client = Anthropic(api_key=self.api_key)
        return self._client

    async def generate(
        self,
        prompt: str,
        model: str = "claude-3-5-sonnet-20241022",
        temperature: float = 0.3,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> LLMResponse:
        response = self.client.messages.create(
            model=model,
            max_tokens=max_tokens or 4096,
            temperature=temperature,
            system="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°å­¦è¯­æ–‡æ•™å¸ˆï¼Œæ“…é•¿è¯„ä»·å’ŒæŒ‡å¯¼å°å­¦ç”Ÿå†™ä½œæ–‡ã€‚",
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        return LLMResponse(
            content=response.content[0].text,
            usage={
                "input_tokens": response.usage.input_tokens,
                "output_tokens": response.usage.output_tokens
            },
            model=model,
            finish_reason=str(response.stop_reason),
            raw_response=response
        )

    def validate_api_key(self, api_key: str) -> bool:
        try:
            client = Anthropic(api_key=api_key)
            return True
        except Exception:
            return False

    def to_config_dict(self, api_key: str) -> Dict[str, Any]:
        return {
            "provider": "anthropic",
            "api_key": api_key,
            "models": self.supported_models
        }
```

### 4.5 Google Gemini Provider å®ç°

```python
# app/services/llm/google.py
from typing import Any, Dict, List, Optional
import google.generativeai as genai

from app.services.llm.base import LLMProvider, LLMResponse


class GoogleProvider(LLMProvider):
    """Google Gemini æœåŠ¡å•†å®ç°"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key
        genai.configure(api_key=api_key)

    @property
    def provider_name(self) -> str:
        return "Google Gemini"

    @property
    def supported_models(self) -> List[str]:
        return ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-1.0-pro"]

    async def generate(
        self,
        prompt: str,
        model: str = "gemini-1.5-pro",
        temperature: float = 0.3,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> LLMResponse:
        generation_config = {
            "temperature": temperature,
            "max_output_tokens": max_tokens or 2048,
        }

        model_instance = genai.GenerativeModel(
            model_name=model,
            generation_config=generation_config,
            system_instruction="ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°å­¦è¯­æ–‡æ•™å¸ˆï¼Œæ“…é•¿è¯„ä»·å’ŒæŒ‡å¯¼å°å­¦ç”Ÿå†™ä½œæ–‡ã€‚"
        )

        response = model_instance.generate_content(prompt)

        return LLMResponse(
            content=response.text,
            model=model,
            raw_response=response
        )

    def validate_api_key(self, api_key: str) -> bool:
        try:
            genai.configure(api_key=api_key)
            models = genai.list_models()
            return len(list(models)) > 0
        except Exception:
            return False

    def to_config_dict(self, api_key: str) -> Dict[str, Any]:
        return {
            "provider": "google",
            "api_key": api_key,
            "models": self.supported_models
        }
```

### 4.6 å›½å†…æ¨¡å‹æœåŠ¡å•†å®ç°

#### 4.6.1 ç™¾åº¦æ–‡å¿ƒ

```python
# app/services/llm/baidu.py
from typing import Any, Dict, List, Optional
import requests

from app.services.llm.base import LLMProvider, LLMResponse


class BaiduProvider(LLMProvider):
    """ç™¾åº¦æ–‡å¿ƒä¸€è¨€æœåŠ¡å•†å®ç°"""

    def __init__(self, api_key: Optional[str] = None, secret_key: Optional[str] = None):
        self.api_key = api_key
        self.secret_key = secret_key
        self._access_token: Optional[str] = None

    @property
    def provider_name(self) -> str:
        return "ç™¾åº¦æ–‡å¿ƒä¸€è¨€"

    @property
    def supported_models(self) -> List[str]:
        return ["ernie-4.0-8k", "ernie-3.5-8k", "ernie-speed-8k"]

    def _get_access_token(self) -> str:
        """è·å–ç™¾åº¦è®¿é—®ä»¤ç‰Œ"""
        if self._access_token:
            return self._access_token

        url = "https://aip.baidubce.com/oauth/2.0/token"
        params = {
            "grant_type": "client_credentials",
            "client_id": self.api_key,
            "client_secret": self.secret_key
        }
        response = requests.post(url, params=params)
        self._access_token = response.json().get("access_token")
        return self._access_token

    async def generate(
        self,
        prompt: str,
        model: str = "ernie-3.5-8k",
        temperature: float = 0.3,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> LLMResponse:
        access_token = self._get_access_token()
        url = f"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/{model}"

        headers = {"Content-Type": "application/json"}
        payload = {
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°å­¦è¯­æ–‡æ•™å¸ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": temperature,
            "max_output_tokens": max_tokens or 2048
        }

        response = requests.post(url, params={"access_token": access_token}, json=payload, headers=headers)

        return LLMResponse(
            content=response.json().get("result", ""),
            model=model,
            raw_response=response.json()
        )

    def validate_api_key(self, api_key: str) -> bool:
        # ç™¾åº¦éœ€è¦ api_key å’Œ secret_key é…å¯¹éªŒè¯
        return bool(api_key and self.secret_key)

    def to_config_dict(self, api_key: str) -> Dict[str, Any]:
        return {
            "provider": "baidu",
            "api_key": api_key,
            "secret_key": self.secret_key,
            "models": self.supported_models
        }
```

#### 4.6.2 é˜¿é‡Œé€šä¹‰

```python
# app/services/llm/aliyun.py
from typing import Any, Dict, List, Optional
import httpx

from app.services.llm.base import LLMProvider, LLMResponse


class AliyunProvider(LLMProvider):
    """é˜¿é‡Œäº‘é€šä¹‰åƒé—®æœåŠ¡å•†å®ç°"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key

    @property
    def provider_name(self) -> str:
        return "é˜¿é‡Œäº‘é€šä¹‰åƒé—®"

    @property
    def supported_models(self) -> List[str]:
        return ["qwen-turbo", "qwen-plus", "qwen-max"]

    async def generate(
        self,
        prompt: str,
        model: str = "qwen-plus",
        temperature: float = 0.3,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> LLMResponse:
        url = f"https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation/{model}"

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "input": {
                "messages": [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°å­¦è¯­æ–‡æ•™å¸ˆã€‚"},
                    {"role": "user", "content": prompt}
                ]
            },
            "parameters": {
                "temperature": temperature,
                "max_tokens": max_tokens or 2048
            }
        }

        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, headers=headers)

        return LLMResponse(
            content=response.json().get("output", {}).get("text", ""),
            model=model,
            raw_response=response.json()
        )

    def validate_api_key(self, api_key: str) -> bool:
        return bool(api_key)

    def to_config_dict(self, api_key: str) -> Dict[str, Any]:
        return {
            "provider": "aliyun",
            "api_key": api_key,
            "models": self.supported_models
        }
```

#### 4.6.3 æ™ºè°±æ¸…è¨€

```python
# app/services/llm/zhipu.py
from typing import Any, Dict, List, Optional
import httpx

from app.services.llm.base import LLMProvider, LLMResponse


class ZhiPuProvider(LLMProvider):
    """æ™ºè°±æ¸…è¨€æœåŠ¡å•†å®ç°"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key

    @property
    def provider_name(self) -> str:
        return "æ™ºè°±æ¸…è¨€"

    @property
    def supported_models(self) -> List[str]:
        return ["glm-4", "glm-4-plus", "glm-4v", "glm-3-turbo"]

    async def generate(
        self,
        prompt: str,
        model: str = "glm-4",
        temperature: float = 0.3,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> LLMResponse:
        url = "https://open.bigmodel.cn/api/paas/v4/chat/completions"

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": model,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°å­¦è¯­æ–‡æ•™å¸ˆã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": temperature,
            "max_tokens": max_tokens or 2048
        }

        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, headers=headers)

        return LLMResponse(
            content=response.json().get("choices", [{}])[0].get("message", {}).get("content", ""),
            model=model,
            raw_response=response.json()
        )

    def validate_api_key(self, api_key: str) -> bool:
        return bool(api_key)

    def to_config_dict(self, api_key: str) -> Dict[str, Any]:
        return {
            "provider": "zhipu",
            "api_key": api_key,
            "models": self.supported_models
        }
```

### 4.7 æ¨¡å‹å·¥å‚ä¸è‡ªå®šä¹‰æ¨¡å‹

```python
# app/services/llm/factory.py
from typing import Any, Dict, List, Optional, Type
from app.services.llm.base import LLMProvider
from app.services.llm.openai import OpenAIProvider
from app.services.llm.anthropic import AnthropicProvider
from app.services.llm.google import GoogleProvider
from app.services.llm.baidu import BaiduProvider
from app.services.llm.aliyun import AliyunProvider
from app.services.llm.zhipu import ZhiPuProvider


class LLMFactory:
    """LLM æœåŠ¡å•†å·¥å‚"""

    _providers: Dict[str, Type[LLMProvider]] = {
        "openai": OpenAIProvider,
        "anthropic": AnthropicProvider,
        "google": GoogleProvider,
        "baidu": BaiduProvider,
        "aliyun": AliyunProvider,
        "zhipu": ZhiPuProvider,
    }

    @classmethod
    def register_provider(cls, name: str, provider_class: Type[LLMProvider]) -> None:
        """æ³¨å†Œè‡ªå®šä¹‰æ¨¡å‹æœåŠ¡å•†"""
        cls._providers[name] = provider_class

    @classmethod
    def get_provider(
        cls,
        provider_name: str,
        api_key: Optional[str] = None,
        **kwargs
    ) -> LLMProvider:
        """è·å–æŒ‡å®šæœåŠ¡å•†å®ä¾‹"""
        provider_class = cls._providers.get(provider_name.lower())
        if not provider_class:
            raise ValueError(f"Unknown provider: {provider_name}")
        return provider_class(api_key=api_key, **kwargs)

    @classmethod
    def list_providers(cls) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æœåŠ¡å•†"""
        return list(cls._providers.keys())

    @classmethod
    def get_provider_info(cls, provider_name: str) -> Dict[str, Any]:
        """è·å–æœåŠ¡å•†ä¿¡æ¯"""
        provider_class = cls._providers.get(provider_name.lower())
        if not provider_class:
            return {}
        provider = provider_class()
        return {
            "name": provider.provider_name,
            "models": provider.supported_models
        }


# è‡ªå®šä¹‰æ¨¡å‹æœåŠ¡å•†ç¤ºä¾‹
class CustomOpenAICompatibleProvider(LLMProvider):
    """è‡ªå®šä¹‰ OpenAI å…¼å®¹ API æœåŠ¡å•†"""

    def __init__(
        self,
        api_key: str,
        base_url: str,
        provider_name: str = "è‡ªå®šä¹‰æ¨¡å‹",
        supported_models: List[str] = None
    ):
        self.api_key = api_key
        self.base_url = base_url
        self._provider_name = provider_name
        self._supported_models = supported_models or ["custom-model"]
        self._client = None

    @property
    def provider_name(self) -> str:
        return self._provider_name

    @property
    def supported_models(self) -> List[str]:
        return self._supported_models

    async def generate(
        self,
        prompt: str,
        model: str = "custom-model",
        temperature: float = 0.3,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> LLMResponse:
        # å®ç° OpenAI å…¼å®¹çš„ API è°ƒç”¨
        import httpx

        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{self.base_url}/chat/completions",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={
                    "model": model,
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°å­¦è¯­æ–‡æ•™å¸ˆã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "max_tokens": max_tokens
                }
            )

        return LLMResponse(
            content=response.json().get("choices", [{}])[0].get("message", {}).get("content", ""),
            model=model,
            raw_response=response.json()
        )

    def validate_api_key(self, api_key: str) -> bool:
        return bool(api_key and self.base_url)

    def to_config_dict(self, api_key: str) -> Dict[str, Any]:
        return {
            "provider": "custom",
            "api_key": api_key,
            "base_url": self.base_url,
            "name": self._provider_name,
            "models": self._supported_models
        }


def register_custom_provider(
    name: str,
    provider_name: str,
    base_url: str,
    supported_models: List[str]
) -> None:
    """ä¾¿æ·çš„è‡ªå®šä¹‰æ¨¡å‹æ³¨å†Œå‡½æ•°"""
    class CustomProvider(CustomOpenAICompatibleProvider):
        pass

    CustomProvider.__name__ = f"Custom{name.title()}Provider"
    LLMFactory.register_provider(name, CustomProvider)
```

### 4.8 è¯„åˆ†å¼•æ“

```python
# app/services/scoring/engine.py
import json
import re
from typing import Any, Dict, List, Optional, Tuple
from pydantic import BaseModel

from app.services.llm.base import LLMProvider, EssayScoringTemplate
from app.services.essay.classifier import EssayClassifier


class DimensionScore(BaseModel):
    """ç»´åº¦å¾—åˆ†"""
    name: str
    score: float
    max_score: float
    comment: str


class ScoringResult(BaseModel):
    """è¯„åˆ†ç»“æœ"""
    total_score: int
    grade: str
    dimensions: Dict[str, DimensionScore]
    strengths: List[str]
    weaknesses: List[str]
    suggestions: List[str]
    essay_type_analysis: Dict[str, Any]


class EssayScoringEngine:
    """ä½œæ–‡è¯„åˆ†å¼•æ“"""

    def __init__(self, llm_provider: LLMProvider):
        self.llm_provider = llm_provider
        self.essay_classifier = EssayClassifier()

    async def score_essay(
        self,
        essay_content: str,
        essay_title: Optional[str],
        grade: str,
        essay_type: Optional[str] = None
    ) -> ScoringResult:
        # 1. è‡ªåŠ¨è¯†åˆ«å†™ä½œç±»å‹ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
        if not essay_type:
            identified_type = await self.essay_classifier.classify(essay_content)
        else:
            identified_type = essay_type

        # 2. æ„å»ºè¯„åˆ†æç¤ºè¯
        prompt = EssayScoringTemplate.build_scoring_prompt(
            essay_content=essay_content,
            essay_title=essay_title,
            grade=grade,
            essay_type=identified_type
        )

        # 3. è°ƒç”¨ LLM è¯„åˆ†
        response = await self.llm_provider.generate(
            prompt=prompt,
            model="gpt-4-turbo",  # å¯é…ç½®
            temperature=0.3,
            max_tokens=4096
        )

        # 4. è§£æç»“æœ
        result = self._parse_response(response.content)

        # 5. éªŒè¯æ€»åˆ†
        total = sum(dim.score for dim in result.dimensions.values())
        if abs(total - result.total_score) > 2:
            result.total_score = int(total)

        return result

    def _parse_response(self, content: str) -> ScoringResult:
        """è§£æ LLM è¿”å›çš„ JSON ç»“æœ"""
        # æå– JSON
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', content)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å°è¯•ç›´æ¥è§£æ
            json_str = content

        data = json.loads(json_str)

        # æ„å»ºç»´åº¦å¾—åˆ†
        dimensions = {}
        for key, dim_data in data.get("dimensions", {}).items():
            dimensions[key] = DimensionScore(
                name=dim_data.get("name", key),
                score=dim_data.get("score", 0),
                max_score=dim_data.get("max_score", 0),
                comment=dim_data.get("comment", "")
            )

        return ScoringResult(
            total_score=data.get("total_score", 0),
            grade=data.get("grade", "åˆæ ¼"),
            dimensions=dimensions,
            strengths=data.get("strengths", []),
            weaknesses=data.get("weaknesses", []),
            suggestions=data.get("suggestions", []),
            essay_type_analysis=data.get("essay_type_analysis", {})
        )

    def calculate_grade(self, total_score: int) -> str:
        """è®¡ç®—è¯„çº§"""
        if total_score >= 85:
            return "ä¼˜ç§€"
        elif total_score >= 70:
            return "è‰¯å¥½"
        elif total_score >= 60:
            return "åˆæ ¼"
        else:
            return "å¾…æé«˜"
```

### 4.9 ä½œæ–‡è§£æå™¨

```python
# app/services/scoring/parser.py
import re
from typing import Any, Dict, List, Tuple
from collections import Counter


class EssayParser:
    """ä½œæ–‡è§£æå™¨"""

    # å¸¸ç”¨å­—è¯åº“ï¼ˆç®€åŒ–ç‰ˆç¤ºä¾‹ï¼‰
    COMMON_WORDS = set([
        "çš„", "äº†", "æ˜¯", "æˆ‘", "ä½ ", "ä»–", "å¥¹", "å®ƒ", "ä»¬", "è¿™", "é‚£",
        "æœ‰", "åœ¨", "æ¥", "å»", "çœ‹", "è¯´", "å«", "æƒ³", "åš", "åˆ°",
        # ... æ›´å¤šå¸¸ç”¨å­—
    ])

    # å¸¸è§é”™åˆ«å­—å¯¹ç…§
    TYPO_CORRECTIONS = {
        "å·²ç»": "å·²ç»",
        "ä»¥ç»": "å·²ç»",
        "åœ¨å†": "åœ¨",
        "å†åœ¨": "å†",
        "è±¡åƒ": "åƒ",
        "åƒè±¡": "åƒ",
        "å·±å·²": "å·²",
        "å·²å·±": "å·±",
        "æŠ˜/çœŸ": "çœŸ",
        "å‡/ç”²": "å‡",
    }

    def __init__(self):
        self.chinese_char_pattern = re.compile(r'[\u4e00-\u9fa5]')

    def parse(self, content: str) -> Dict[str, Any]:
        """è§£æä½œæ–‡å†…å®¹"""
        return {
            "total_characters": self._count_characters(content),
            "words_without_punctuation": self._count_words(content),
            "sentence_count": self._count_sentences(content),
            "paragraph_count": self._count_paragraphs(content),
            "average_sentence_length": self._calc_avg_sentence_length(content),
            "vocabulary_richness": self._calc_vocabulary_richness(content),
            "potential_typos": self._find_potential_typos(content),
            "punctuation_usage": self._analyze_punctuation(content),
        }

    def _count_characters(self, content: str) -> int:
        """ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•°"""
        return len(self.chinese_char_pattern.findall(content))

    def _count_words(self, content: str) -> int:
        """ç»Ÿè®¡å»æ ‡ç‚¹åçš„å­—æ•°"""
        cleaned = re.sub(r'[^\w\s]', '', content)
        return len(cleaned)

    def _count_sentences(self, content: str) -> int:
        """ç»Ÿè®¡å¥å­æ•°é‡"""
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
        return len([s for s in sentences if s.strip()])

    def _count_paragraphs(self, content: str) -> int:
        """ç»Ÿè®¡æ®µè½æ•°é‡"""
        paragraphs = [p for p in content.split('\n\n') if p.strip()]
        return max(len(paragraphs), 1)

    def _calc_avg_sentence_length(self, content: str) -> float:
        """è®¡ç®—å¹³å‡å¥é•¿"""
        char_count = self._count_characters(content)
        sentence_count = self._count_sentences(content)
        if sentence_count == 0:
            return 0
        return round(char_count / sentence_count, 2)

    def _calc_vocabulary_richness(self, content: str) -> Dict[str, Any]:
        """è®¡ç®—è¯æ±‡ä¸°å¯Œåº¦"""
        words = re.findall(r'[\u4e00-\u9fa5]{2,}', content)
        if not words:
            return {"unique_count": 0, "total_count": 0, "richness": 0}
        
        unique_words = set(words)
        richness = len(unique_words) / len(words) if words else 0
        
        return {
            "unique_count": len(unique_words),
            "total_count": len(words),
            "richness": round(richness, 3)
        }

    def _find_potential_typos(self, content: str) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾å¯èƒ½çš„é”™åˆ«å­—"""
        potential_typos = []
        for wrong, correct in self.TYPO_CORRECTIONS.items():
            if wrong in content:
                count = content.count(wrong)
                potential_typos.append({
                    "wrong": wrong,
                    "correct": correct,
                    "count": count,
                    "suggestion": f"'{wrong}' åº”ä¸º '{correct}'"
                })
        return potential_typos

    def _analyze_punctuation(self, content: str) -> Dict[str, Any]:
        """åˆ†ææ ‡ç‚¹ä½¿ç”¨"""
        punctuation_counts = Counter(content)
        total = len(content)
        
        return {
            "comma_count": punctuation_counts.get('ï¼Œ', 0),
            "period_count": punctuation_counts.get('ã€‚', 0),
            "question_mark_count": punctuation_counts.get('ï¼Ÿ', 0),
            "exclamation_count": punctuation_counts.get('ï¼', 0),
            "colon_count": punctuation_counts.get('ï¼š', 0),
            "semicolon_count": punctuation_counts.get('ï¼›', 0),
            "quotation_count": punctuation_counts.get('"', 0) + punctuation_counts.get('"', 0),
        }

    def roundtrip_validation(self, original: str, parsed_data: Dict[str, Any]) -> bool:
        """å¾€è¿”éªŒè¯ï¼šç¡®ä¿è§£æç»“æœå¯é‡ç°"""
        # éªŒè¯å­—æ•°ç»Ÿè®¡
        recalculated_chars = self._count_characters(original)
        if recalculated_chars != parsed_data["total_characters"]:
            return False

        # éªŒè¯å¥å­æ•°
        recalculated_sentences = self._count_sentences(original)
        if recalculated_sentences != parsed_data["sentence_count"]:
            return False

        return True
```

## 10. æ‰¹é‡å¤„ç†ä¸å­˜å‚¨è®¾è®¡

### 10.1 æ–‡ä»¶ä¸Šä¼ å¤„ç†

```python
# app/services/file/processor.py
import os
import zipfile
import hashlib
from pathlib import Path
from typing import List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from pydantic import BaseModel


class FileType(Enum):
    DOC = ".doc"
    DOCX = ".docx"
    MD = ".md"
    TXT = ".txt"
    ZIP = ".zip"


@dataclass
class ProcessedFile:
    """å¤„ç†åçš„æ–‡ä»¶"""
    original_name: str
    file_type: FileType
    content: str
    file_size: int
    checksum: str
    temp_path: Optional[str] = None


class FileProcessor:
    """æ–‡ä»¶å¤„ç†å™¨"""

    # æ”¯æŒçš„æ–‡ä»¶ç±»å‹
    SUPPORTED_TYPES = {".doc", ".docx", ".md", ".txt", ".zip"}

    # æœ€å¤§æ–‡ä»¶å¤§å° (10MB)
    MAX_FILE_SIZE = 10 * 1024 * 1024

    # ZIPè§£å‹é™åˆ¶
    MAX_ZIP_FILES = 100
    MAX_ZIP_DEPTH = 3
    MAX_UNZIP_SIZE = 500 * 1024 * 1024  # 500MB

    def __init__(self, temp_dir: str = "/tmp/essay_processor"):
        self.temp_dir = Path(temp_dir)
        self.temp_dir.mkdir(parents=True, exist_ok=True)

    async def process_upload(
        self,
        file_content: bytes,
        filename: str
    ) -> ProcessedFile:
        """å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        # 1. éªŒè¯æ–‡ä»¶ç±»å‹
        file_ext = Path(filename).suffix.lower()
        if file_ext not in self.SUPPORTED_TYPES:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")

        # 2. éªŒè¯æ–‡ä»¶å¤§å°
        if len(file_content) > self.MAX_FILE_SIZE:
            raise ValueError(f"æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶: {len(file_content)} > {self.MAX_FILE_SIZE}")

        # 3. è®¡ç®—æ ¡éªŒå’Œ
        checksum = hashlib.md5(file_content).hexdigest()

        # 4. æ ¹æ®ç±»å‹å¤„ç†
        if file_ext == ".zip":
            return await self._process_zip(file_content, filename, checksum)
        else:
            return self._process_document(file_content, filename, file_ext, checksum)

    def _process_document(
        self,
        content: bytes,
        filename: str,
        file_ext: str,
        checksum: str
    ) -> ProcessedFile:
        """å¤„ç†æ™®é€šæ–‡æ¡£"""
        if file_ext == ".docx":
            text = self._parse_docx(content)
        elif file_ext == ".md":
            text = content.decode("utf-8")
        elif file_ext == ".txt":
            text = content.decode("utf-8")
        else:
            text = content.decode("utf-8", errors="ignore")

        return ProcessedFile(
            original_name=filename,
            file_type=self._ext_to_filetype(file_ext),
            content=text,
            file_size=len(content),
            checksum=checksum
        )

    async def _process_zip(
        self,
        content: bytes,
        filename: str,
        checksum: str
    ) -> ProcessedFile:
        """å¤„ç†ZIPå‹ç¼©åŒ…"""
        temp_zip_path = self.temp_dir / f"zip_{checksum}.zip"

        try:
            # å†™å…¥ä¸´æ—¶ZIPæ–‡ä»¶
            with open(temp_zip_path, "wb") as f:
                f.write(content)

            # è§£å‹éªŒè¯
            with zipfile.ZipFile(temp_zip_path, "r") as zf:
                # éªŒè¯æ–‡ä»¶æ•°é‡
                if len(zf.namelist()) > self.MAX_ZIP_FILES:
                    raise ValueError(f"ZIPæ–‡ä»¶åŒ…å«è¿‡å¤šæ–‡ä»¶: {len(zf.namelist())}")

                # éªŒè¯è§£å‹å¤§å°
                total_size = sum(info.file_size for info in zf.infolist())
                if total_size > self.MAX_UNZIP_SIZE:
                    raise ValueError(f"è§£å‹åæ€»å¤§å°è¶…è¿‡é™åˆ¶: {total_size}")

                # è§£å‹åˆ°ä¸´æ—¶ç›®å½•
                extract_dir = self.temp_dir / f"extract_{checksum}"
                extract_dir.mkdir(exist_ok=True)
                zf.extractall(extract_dir)

                # å¤„ç†æ‰€æœ‰æ–‡ä»¶
                all_content = []
                success_count = 0
                fail_count = 0
                fail_files = []

                for file_path in self._iterate_files(extract_dir):
                    try:
                        file_content = self._process_single_file(file_path)
                        all_content.append(file_content)
                        success_count += 1
                    except Exception as e:
                        fail_count += 1
                        fail_files.append((str(file_path), str(e)))

                # ç”Ÿæˆæ±‡æ€»ä¿¡æ¯
                summary = f"\n\n=== ZIPå¤„ç†æ±‡æ€» ===\n"
                summary += f"æˆåŠŸå¤„ç†: {success_count} ä¸ªæ–‡ä»¶\n"
                summary += f"å¤„ç†å¤±è´¥: {fail_count} ä¸ªæ–‡ä»¶\n"
                if fail_files:
                    summary += "å¤±è´¥æ–‡ä»¶åˆ—è¡¨:\n"
                    for path, error in fail_files:
                        summary += f"  - {path}: {error}\n"

            # åˆå¹¶æ‰€æœ‰å†…å®¹
            combined_content = "\n\n".join(f.content for f in all_content) + summary

            return ProcessedFile(
                original_name=filename,
                file_type=FileType.ZIP,
                content=combined_content,
                file_size=len(content),
                checksum=checksum,
                temp_path=str(extract_dir)
            )

        finally:
            # æ¸…ç†ï¼šåˆ é™¤åŸå§‹ZIPæ–‡ä»¶
            if temp_zip_path.exists():
                temp_zip_path.unlink()

    def _iterate_files(self, directory: Path) -> List[Path]:
        """éå†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆé™åˆ¶æ·±åº¦ï¼‰"""
        files = []
        for path in directory.rglob("*"):
            if path.is_file():
                # æ£€æŸ¥æ·±åº¦
                depth = len(path.relative_to(directory).parts)
                if depth > self.MAX_ZIP_DEPTH:
                    continue
                files.append(path)
        return files

    def _process_single_file(self, file_path: Path) -> ProcessedFile:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        with open(file_path, "rb") as f:
            content = f.read()

        file_ext = file_path.suffix.lower()
        if file_ext not in self.SUPPORTED_TYPES:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")

        return self._process_document(
            content,
            file_path.name,
            file_ext,
            hashlib.md5(content).hexdigest()
        )

    def _parse_docx(self, content: bytes) -> str:
        """è§£ædocxæ–‡ä»¶"""
        from docx import Document

        doc = Document(content)
        paragraphs = []

        for para in doc.paragraphs:
            if para.text.strip():
                paragraphs.append(para.text)

        # æå–è¡¨æ ¼å†…å®¹
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    if cell.text.strip():
                        paragraphs.append(cell.text)

        return "\n".join(paragraphs)

    def _ext_to_filetype(self, ext: str) -> FileType:
        """æ‰©å±•åè½¬æ¢ä¸ºæ–‡ä»¶ç±»å‹æšä¸¾"""
        mapping = {
            ".doc": FileType.DOC,
            ".docx": FileType.DOCX,
            ".md": FileType.MD,
            ".txt": FileType.TXT,
            ".zip": FileType.ZIP,
        }
        return mapping.get(ext.lower(), FileType.TXT)

    async def cleanup(self, temp_path: Optional[str]) -> None:
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        if temp_path and Path(temp_path).exists():
            import shutil
            shutil.rmtree(temp_path, ignore_errors=True)
```

### 10.2 é˜¿é‡Œäº‘OSSå­˜å‚¨

```python
# app/services/storage/oss.py
import os
from datetime import datetime
from pathlib import Path
from typing import Optional, BinaryIO
from dataclasses import dataclass

import oss2
from oss2.credentials import Credentials

from app.core.config import settings


@dataclass
class OSSConfig:
    """OSSé…ç½®"""
    access_key_id: str
    access_key_secret: str
    bucket_name: str
    endpoint: str
    cdn_domain: Optional[str] = None


class OSSStorage:
    """é˜¿é‡Œäº‘OSSå­˜å‚¨æœåŠ¡"""

    def __init__(self, config: Optional[OSSConfig] = None):
        self.config = config or self._load_config_from_settings()
        self._bucket: Optional[oss2.Bucket] = None

    def _load_config_from_settings(self) -> OSSConfig:
        """ä»è®¾ç½®åŠ è½½é…ç½®"""
        return OSSConfig(
            access_key_id=settings.OSS_ACCESS_KEY_ID,
            access_key_secret=settings.OSS_ACCESS_KEY_SECRET,
            bucket_name=settings.OSS_BUCKET_NAME,
            endpoint=settings.OSS_ENDPOINT,
            cdn_domain=settings.OSS_CDN_DOMAIN
        )

    @property
    def bucket(self) -> oss2.Bucket:
        """è·å–OSS Bucketå®ä¾‹"""
        if self._bucket is None:
            credentials = Credentials(
                self.config.access_key_id,
                self.config.access_key_secret
            )
            self._bucket = oss2.Bucket(
                credentials,
                self.config.endpoint,
                self.config.bucket_name
            )
        return self._bucket

    def _build_path(
        self,
        user_id: str,
        essay_id: Optional[str] = None,
        filename: Optional[str] = None
    ) -> str:
        """æ„å»ºå­˜å‚¨è·¯å¾„ï¼š{user_id}/{year}/{month}/{day}/{essay_id}/{filename}"""
        now = datetime.utcnow()
        path_parts = [
            user_id,
            now.strftime("%Y"),
            now.strftime("%m"),
            now.strftime("%d")
        ]

        if essay_id:
            path_parts.append(essay_id)
            if filename:
                path_parts.append(filename)

        return "/".join(path_parts)

    async def upload_file(
        self,
        file_content: bytes,
        user_id: str,
        essay_id: str,
        filename: str,
        content_type: str = "application/octet-stream"
    ) -> str:
        """ä¸Šä¼ æ–‡ä»¶åˆ°OSS"""
        object_key = self._build_path(user_id, essay_id, filename)

        # åŒæ­¥ä¸Šä¼ 
        self.bucket.put_object(
            object_key,
            file_content,
            headers={"Content-Type": content_type}
        )

        return self._get_url(object_key)

    async def upload_multiple(
        self,
        files: List[Tuple[str, bytes]],  # (filename, content)
        user_id: str,
        essay_id: str
    ) -> List[str]:
        """æ‰¹é‡ä¸Šä¼ æ–‡ä»¶"""
        urls = []
        for filename, content in files:
            url = await self.upload_file(content, user_id, essay_id, filename)
            urls.append(url)
        return urls

    def download_file(self, object_key: str) -> bytes:
        """ä»OSSä¸‹è½½æ–‡ä»¶"""
        return self.bucket.get_object(object_key).read()

    def delete_file(self, object_key: str) -> None:
        """åˆ é™¤OSSæ–‡ä»¶"""
        self.bucket.delete_object(object_key)

    def delete_multiple(self, object_keys: List[str]) -> None:
        """æ‰¹é‡åˆ é™¤OSSæ–‡ä»¶"""
        self.bucket.batch_delete_objects(object_keys)

    def list_files(
        self,
        user_id: str,
        year: Optional[str] = None,
        month: Optional[str] = None,
        day: Optional[str] = None,
        essay_id: Optional[str] = None
    ) -> List[str]:
        """åˆ—å‡ºæ–‡ä»¶"""
        prefix = self._build_path(user_id, essay_id)
        if year:
            prefix = f"{prefix}/{year}"
        if month:
            prefix = f"{prefix}/{month}"
        if day:
            prefix = f"{prefix}/{day}"

        files = []
        for obj in oss2.ObjectIterator(self.bucket, prefix=prefix):
            files.append(obj.key)

        return files

    def _get_url(self, object_key: str) -> str:
        """è·å–æ–‡ä»¶è®¿é—®URL"""
        if self.config.cdn_domain:
            return f"https://{self.config.cdn_domain}/{object_key}"
        return f"https://{self.config.bucket_name}.{self.config.endpoint}/{object_key}"

    def get_usage_stats(self, user_id: str) -> dict:
        """è·å–ç”¨æˆ·å­˜å‚¨ä½¿ç”¨é‡ç»Ÿè®¡"""
        prefix = f"{user_id}/"
        total_size = 0
        file_count = 0

        for obj in oss2.ObjectIterator(self.bucket, prefix=prefix):
            total_size += obj.size
            file_count += 1

        return {
            "total_size_bytes": total_size,
            "total_size_mb": round(total_size / (1024 * 1024), 2),
            "file_count": file_count
        }
```

### 10.3 å¥–é¡¹é…ç½®ä¸åˆ†æ•°çº¦æŸ

```python
# app/services/awards/manager.py
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple
from enum import Enum
from pydantic import BaseModel


class AwardLevel(Enum):
    """å¥–é¡¹ç­‰çº§"""
    FIRST = "ä¸€ç­‰å¥–"
    SECOND = "äºŒç­‰å¥–"
    THIRD = "ä¸‰ç­‰å¥–"
    CUSTOM = "è‡ªå®šä¹‰"


@dataclass
class AwardConfig:
    """å¥–é¡¹é…ç½®"""
    name: str
    count: int
    icon: Optional[str] = None
    description: Optional[str] = None
    sort_order: int = 0


@dataclass
class AwardResult:
    """å¥–é¡¹è¯„é€‰ç»“æœ"""
    award_name: str
    threshold: float  # è¯¥å¥–é¡¹çš„æœ€ä½åˆ†æ•°é—¨æ§›
    essays: List["EssayResult"]


@dataclass
class EssayResult:
    """ä½œæ–‡è¯„é€‰ç»“æœ"""
    essay_id: str
    student_name: str
    title: str
    score: float
    award: Optional[str] = None


class AwardManager:
    """å¥–é¡¹ç®¡ç†å™¨"""

    # é¢„è®¾æ¨¡æ¿
    TEMPLATES = {
        "ç«èµ›": [
            AwardConfig("ç‰¹ç­‰å¥–", 1, "ğŸ†", "å…¨åœºæœ€é«˜è£èª‰", 0),
            AwardConfig("ä¸€ç­‰å¥–", 3, "ğŸ¥‡", "å“è¶Šè¡¨ç°", 1),
            AwardConfig("äºŒç­‰å¥–", 5, "ğŸ¥ˆ", "ä¼˜ç§€è¡¨ç°", 2),
            AwardConfig("ä¸‰ç­‰å¥–", 10, "ğŸ¥‰", "è‰¯å¥½è¡¨ç°", 3),
        ],
        "ç­çº§": [
            AwardConfig("ä¸€ç­‰å¥–", 1, "ğŸ¥‡", "æœ€ä½³ä½œå“", 0),
            AwardConfig("äºŒç­‰å¥–", 3, "ğŸ¥ˆ", "ä¼˜ç§€ä½œå“", 1),
            AwardConfig("ä¸‰ç­‰å¥–", 5, "ğŸ¥‰", "è‰¯å¥½ä½œå“", 2),
        ],
        "é¼“åŠ±": [
            AwardConfig("ä¼˜ç§€å¥–", 10, "â­", "å€¼å¾—é¼“åŠ±", 0),
            AwardConfig("è¿›æ­¥å¥–", 15, "ğŸ“ˆ", "æ˜¾è‘—è¿›æ­¥", 1),
        ]
    }

    def __init__(self, awards: List[AwardConfig]):
        """åˆå§‹åŒ–å¥–é¡¹é…ç½®"""
        self.awards = sorted(awards, key=lambda x: x.sort_order)
        self._validate_awards()

    def _validate_awards(self) -> None:
        """éªŒè¯å¥–é¡¹é…ç½®"""
        if not self.awards:
            raise ValueError("è‡³å°‘éœ€è¦ä¸€ä¸ªå¥–é¡¹é…ç½®")

        total_count = sum(a.count for a in self.awards)
        if total_count <= 0:
            raise ValueError("å¥–é¡¹æ•°é‡å¿…é¡»å¤§äº0")

    @classmethod
    def from_template(cls, template_name: str) -> "AwardManager":
        """ä»é¢„è®¾æ¨¡æ¿åˆ›å»ºå¥–é¡¹é…ç½®"""
        awards = cls.TEMPLATES.get(template_name)
        if not awards:
            raise ValueError(f"æœªçŸ¥æ¨¡æ¿: {template_name}")
        return cls(awards.copy())

    def calculate_thresholds(
        self,
        essays: List[EssayResult]
    ) -> List[AwardResult]:
        """æ ¹æ®åˆ†æ•°è®¡ç®—å„å¥–é¡¹é—¨æ§›å’Œè·å¥–åå•

        è§„åˆ™ï¼š
        - ä¸€ç­‰å¥– 1 åï¼šå–æœ€é«˜åˆ† 1 ç¯‡ï¼Œå…¶åˆ†æ•°ä¸º Xï¼Œåˆ™å…¶ä»–ä½œæ–‡åˆ†æ•°å¿…é¡» < X
        - äºŒç­‰å¥– N åï¼šå–æ¬¡é«˜åˆ† N ç¯‡ï¼Œå…¶æœ€ä½åˆ†æ•°ä¸º Yï¼Œåˆ™å…¶ä»–ä½œæ–‡åˆ†æ•°å¿…é¡» < Y
        - ä¸‰ç­‰å¥– M åï¼šå–ç¬¬ä¸‰é«˜åˆ† M ç¯‡ï¼Œå…¶æœ€ä½åˆ†æ•°ä¸º Zï¼Œåˆ™å…¶ä»–ä½œæ–‡åˆ†æ•°å¿…é¡» < Z
        """
        if not essays:
            return []

        # æŒ‰åˆ†æ•°é™åºæ’åº
        sorted_essays = sorted(essays, key=lambda x: x.score, reverse=True)

        results: List[AwardResult] = []
        current_index = 0

        for award in self.awards:
            count = award.count

            # è·å–è¯¥å¥–é¡¹çš„ä½œæ–‡
            start_idx = current_index
            end_idx = min(start_idx + count, len(sorted_essays))

            if start_idx >= len(sorted_essays):
                # æ²¡æœ‰æ›´å¤šä½œæ–‡å¯ä¾›è¯„é€‰
                break

            award_essays = sorted_essays[start_idx:end_idx]

            # ç¡®å®šé—¨æ§›åˆ†æ•°
            if award_essays:
                threshold = award_essays[-1].score  # è¯¥å¥–é¡¹æœ€ä½åˆ†
            else:
                threshold = 0

            # æ ‡è®°è·å¥–
            for essay in award_essays:
                essay.award = award.name

            results.append(AwardResult(
                award_name=award.name,
                threshold=threshold,
                essays=award_essays
            ))

            current_index = end_idx

        # å¤„ç†æœªè·å¥–çš„ä½œæ–‡
        for essay in sorted_essays[current_index:]:
            essay.award = None

        return results

    def apply_score_constraints(
        self,
        essays: List[EssayResult]
    ) -> Tuple[List[AwardResult], List[EssayResult]]:
        """åº”ç”¨åˆ†æ•°çº¦æŸå¹¶è¿”å›ç»“æœ

        çº¦æŸè§„åˆ™ï¼š
        - ä¸€ç­‰å¥– X åˆ†ï¼šå…¶ä»–ä½œæ–‡å¿…é¡» < X
        - äºŒç­‰å¥– Y åˆ†ï¼šå…¶ä»–ä½œæ–‡å¿…é¡» < Y
        - ä¸‰ç­‰å¥– Z åˆ†ï¼šå…¶ä»–ä½œæ–‡å¿…é¡» < Z
        """
        results = self.calculate_thresholds(essays)

        # æ”¶é›†é—¨æ§›åˆ†æ•°
        thresholds = {}
        for result in results:
            thresholds[result.award_name] = result.threshold

        # é‡æ–°éªŒè¯æ‰€æœ‰åˆ†æ•°
        awarded_ids = set()
        for essay in essays:
            if essay.award:
                awarded_ids.add(essay.essay_id)

        # ç¡®ä¿æ²¡æœ‰åˆ†æ•°å†²çª
        for essay in essays:
            if essay.essay_id not in awarded_ids:
                # æœªè·å¥–ä½œæ–‡ï¼Œæ£€æŸ¥æ˜¯å¦åº”è¯¥è·å¥–
                for result in results:
                    if essay.score >= result.threshold:
                        # è¿™ç§æƒ…å†µä¸åº”è¯¥å‘ç”Ÿ
                        pass

        return results, essays

    def handle_ties(
        self,
        essays: List[EssayResult],
        results: List[AwardResult]
    ) -> Tuple[List[AwardResult], List[EssayResult]]:
        """å¤„ç†å¹¶åˆ—æƒ…å†µ

        è§„åˆ™ï¼š
        - åŒåˆ†ä½œæ–‡å¹¶åˆ—è·å¥–
        - è‡ªåŠ¨è°ƒæ•´å„å¥–é¡¹æ•°é‡ä»¥å®¹çº³å¹¶åˆ—ä½œæ–‡
        """
        # æŒ‰åˆ†æ•°åˆ†ç»„
        score_groups: Dict[float, List[EssayResult]] = {}
        for essay in essays:
            if essay.score not in score_groups:
                score_groups[essay.score] = []
            score_groups[essay.score].append(essay)

        # æŒ‰åˆ†æ•°é™åºå¤„ç†
        sorted_scores = sorted(score_groups.keys(), reverse=True)

        adjusted_results: List[AwardResult] = []
        current_award_idx = 0
        awarded_ids = set()

        for score in sorted_scores:
            group = score_groups[score]

            if current_award_idx >= len(self.awards):
                # æ‰€æœ‰å¥–é¡¹å·²åˆ†é…å®Œæ¯•
                for essay in group:
                    essay.award = None
                continue

            # åˆ†é…ç»™å½“å‰å¥–é¡¹
            current_award = self.awards[current_award_idx]
            remaining_slots = current_award.count - len(
                e for e in current_award.essays if e.essay_id in awarded_ids
            )

            if remaining_slots > 0:
                # æœ‰å‰©ä½™åé¢ï¼Œåˆ†é…ç»™å½“å‰åˆ†æ•°æ®µ
                for essay in group[:remaining_slots]:
                    essay.award = current_award.name
                    awarded_ids.add(essay.essay_id)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰åŒåˆ†ä½œæ–‡æœªåˆ†é…
                if len(group) > remaining_slots:
                    # å¹¶åˆ—æƒ…å†µï¼šå…¨éƒ¨è·å¥–ï¼Œä½†éœ€è¦è°ƒæ•´
                    for essay in group[remaining_slots:]:
                        essay.award = current_award.name
                        awarded_ids.add(essay.essay_id)

                    # æ ‡è®°ä¸ºå¹¶åˆ—ï¼ˆå¢åŠ åé¢ï¼‰
                    current_award.count = len(
                        e for e in group if e.essay_id in awarded_ids
                    )

            # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªå¥–é¡¹
            current_award_idx += 1

        return adjusted_results, essays

    def get_winners_list(
        self,
        essays: List[EssayResult]
    ) -> List[Dict]:
        """ç”Ÿæˆè·å¥–åå•"""
        results = self.calculate_thresholds(essays)

        winners = []
        for result in results:
            for essay in result.essays:
                winners.append({
                    "award": result.award_name,
                    "threshold": result.threshold,
                    "essay_id": essay.essay_id,
                    "student_name": essay.student_name,
                    "title": essay.title,
                    "score": essay.score
                })

        return winners
```

### 10.4 å¤§æ¨¡å‹ä¸Šä¸‹æ–‡é™åˆ¶å¤„ç†

```python
# app/services/scoring/batch_engine.py
from typing import List, Dict, Optional, Any, Callable
from dataclasses import dataclass, field
import asyncio
import json
from abc import ABC, abstractmethod


@dataclass
class TokenEstimate:
    """Tokenä¼°ç®—"""
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int


@dataclass
class EssayBatch:
    """ä½œæ–‡æ‰¹æ¬¡"""
    essays: List[Dict[str, Any]]  # {"id", "title", "content", ...}
    total_chars: int
    estimated_tokens: int


@dataclass
class BatchScoringResult:
    """åˆ†æ‰¹è¯„åˆ†ç»“æœ"""
    batch_index: int
    results: List[Dict[str, Any]]
    token_usage: TokenEstimate


class ContextLimitHandler:
    """ä¸Šä¸‹æ–‡é™åˆ¶å¤„ç†å™¨"""

    # é»˜è®¤ä¸Šä¸‹æ–‡é™åˆ¶ (128K tokens)
    DEFAULT_CONTEXT_LIMIT = 128 * 1024

    # ä¿ç•™ç»™è¾“å‡ºçš„ tokens
    RESERVED_OUTPUT_TOKENS = 4096

    # æç¤ºè¯åŸºç¡€ tokens ä¼°ç®—
    BASE_PROMPT_TOKENS = 3000

    def __init__(
        self,
        context_limit: int = DEFAULT_CONTEXT_LIMIT,
        reserved_output: int = RESERVED_OUTPUT_TOKENS
    ):
        self.context_limit = context_limit
        self.reserved_output = reserved_output

    def estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„ tokens æ•°é‡ï¼ˆä¸­æ–‡çº¦ 1.5 tokens/å­—ç¬¦ï¼‰"""
        return int(len(text) * 1.5)

    def calculate_available_tokens(self, prompt_overhead: int = BASE_PROMPT_TOKENS) -> int:
        """è®¡ç®—å¯ç”¨äºä½œæ–‡å†…å®¹çš„ tokens"""
        return self.context_limit - prompt_overhead - self.reserved_output

    def compress_essay(self, essay: Dict[str, Any]) -> Dict[str, Any]:
        """å‹ç¼©ä½œæ–‡å†…å®¹ï¼Œä¿ç•™æ ¸å¿ƒä¿¡æ¯"""
        content = essay.get("content", "")

        # å»é™¤å†—ä½™ç©ºç™½
        compressed = self._compress_whitespace(content)

        # ä¿ç•™åŸå§‹é•¿åº¦ä¿¡æ¯
        original_length = len(content)
        compressed_length = len(compressed)

        return {
            **essay,
            "content": compressed,
            "compression_info": {
                "original_length": original_length,
                "compressed_length": compressed_length,
                "ratio": compressed_length / original_length if original_length > 0 else 1
            }
        }

    def _compress_whitespace(self, text: str) -> str:
        """å‹ç¼©ç©ºç™½å­—ç¬¦"""
        # åˆå¹¶å¤šä½™ç©ºè¡Œ
        lines = text.split("\n")
        compressed_lines = []
        prev_empty = False

        for line in lines:
            is_empty = line.strip() == ""
            if is_empty:
                if not prev_empty:
                    compressed_lines.append("")
                prev_empty = True
            else:
                compressed_lines.append(line.strip())
                prev_empty = False

        return "\n".join(compressed_lines)

    def should_use_batching(self, essays: List[Dict[str, Any]]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†æ‰¹å¤„ç†"""
        total_chars = sum(len(e.get("content", "")) for e in essays)
        estimated_tokens = self.estimate_tokens(str(essays))

        available = self.calculate_available_tokens()
        return estimated_tokens > available

    def create_batches(
        self,
        essays: List[Dict[str, Any]],
        batch_callback: Optional[Callable[[EssayBatch], None]] = None
    ) -> List[EssayBatch]:
        """åˆ›å»ºåˆ†æ‰¹è¯„å¤„ç†æ‰¹æ¬¡"""
        available = self.calculate_available_tokens()

        batches: List[EssayBatch] = []
        current_batch: List[Dict[str, Any]] = []
        current_chars = 0

        for essay in essays:
            essay_tokens = self.estimate_tokens(essay.get("content", ""))

            # å‹ç¼©ä½œæ–‡
            compressed = self.compress_essay(essay)
            compressed_tokens = self.estimate_tokens(compressed["content"])

            if current_chars + compressed_tokens > available:
                # å½“å‰æ‰¹æ¬¡å·²æ»¡ï¼Œä¿å­˜å¹¶åˆ›å»ºæ–°æ‰¹æ¬¡
                if current_batch:
                    batch = EssayBatch(
                        essays=current_batch,
                        total_chars=current_chars,
                        estimated_tokens=self.estimate_tokens(str(current_batch))
                    )
                    batches.append(batch)
                    if batch_callback:
                        batch_callback(batch)

                current_batch = []
                current_chars = 0

            current_batch.append(compressed)
            current_chars += compressed_tokens

        # ä¿å­˜æœ€åä¸€ä¸ªæ‰¹æ¬¡
        if current_batch:
            batch = EssayBatch(
                essays=current_batch,
                total_chars=current_chars,
                estimated_tokens=self.estimate_tokens(str(current_batch))
            )
            batches.append(batch)
            if batch_callback:
                batch_callback(batch)

        return batches


class ConsistentScoringEngine:
    """ä¸€è‡´æ€§è¯„åˆ†å¼•æ“

    ç¡®ä¿æ‰€æœ‰ä½œæ–‡ä½¿ç”¨ç›¸åŒçš„è¯„åˆ†æ ‡å‡†è¿›è¡Œè¯„åˆ†
    """

    def __init__(
        self,
        llm_provider,
        context_handler: Optional[ContextLimitHandler] = None
    ):
        self.llm_provider = llm_provider
        self.context_handler = context_handler or ContextLimitHandler()

    async def score_all_consistently(
        self,
        essays: List[Dict[str, Any]],
        grade: str,
        essay_type: str,
        scoring_prompt: str
    ) -> List[Dict[str, Any]]:
        """ä¸€è‡´æ€§åœ°è¯„åˆ†æ‰€æœ‰ä½œæ–‡

        å¤„ç†æµç¨‹ï¼š
        1. åˆæ­¥åˆ†æï¼šå¯¹æ¯ç¯‡ä½œæ–‡è¿›è¡Œåˆæ­¥åˆ†æï¼Œç”Ÿæˆç»“æ„åŒ–æ‘˜è¦
        2. æ¨ªå‘å¯¹æ¯”ï¼šå°†æ‰€æœ‰æ‘˜è¦ç»„åˆï¼Œè°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ¨ªå‘å¯¹æ¯”è¯„åˆ†
        3. äºŒæ¬¡éªŒè¯ï¼šå¯¹é«˜åˆ†å’Œä½åˆ†ä½œæ–‡è¿›è¡ŒäºŒæ¬¡éªŒè¯
        4. æœ€ç»ˆç»“æœï¼šç”Ÿæˆæœ€ç»ˆè¯„åˆ†ç»“æœ
        """
        # Step 1: åˆæ­¥åˆ†æ - ç”Ÿæˆæ¯ç¯‡ä½œæ–‡çš„ç»“æ„åŒ–æ‘˜è¦
        summaries = await self._generate_summaries(essays, grade, essay_type)

        # Step 2: æ¨ªå‘å¯¹æ¯” - ç¡®ä¿è¯„åˆ†æ ‡å‡†ä¸€è‡´
        normalized_scores = await self._normalize_scores(
            summaries, essays, grade, essay_type, scoring_prompt
        )

        # Step 3: äºŒæ¬¡éªŒè¯ - å¯¹å¼‚å¸¸åˆ†æ•°è¿›è¡ŒéªŒè¯
        verified_scores = await self._verify_extreme_scores(
            normalized_scores, essays, grade, essay_type
        )

        return verified_scores

    async def _generate_summaries(
        self,
        essays: List[Dict[str, Any]],
        grade: str,
        essay_type: str
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ¯ç¯‡ä½œæ–‡çš„æ‘˜è¦"""
        summaries = []

        for essay in essays:
            prompt = f"""è¯·å¯¹ä»¥ä¸‹ä½œæ–‡è¿›è¡Œç®€è¦åˆ†æï¼Œæå–å…³é”®ç‰¹å¾ï¼š

å¹´çº§ï¼š{grade}
ç±»å‹ï¼š{essay_type}
æ ‡é¢˜ï¼š{essay.get('title', 'æ— ')}

å†…å®¹ï¼š
{essay.get('content', '')[:2000]}  # é™åˆ¶é•¿åº¦

è¯·ç”¨100å­—ä»¥å†…æ€»ç»“ä»¥ä¸‹è¦ç‚¹ï¼š
1. ä¸»é¢˜ç«‹æ„
2. ç»“æ„ç‰¹ç‚¹
3. è¯­è¨€é£æ ¼
4. ä¸»è¦äº®ç‚¹
5. ä¸»è¦ä¸è¶³
"""
            summary = await self._call_llm(prompt)
            summaries.append({
                "essay_id": essay.get("id"),
                "summary": summary
            })

        return summaries

    async def _normalize_scores(
        self,
        summaries: List[Dict],
        essays: List[Dict],
        grade: str,
        essay_type: str,
        base_prompt: str
    ) -> List[Dict[str, Any]]:
        """æ¨ªå‘å¯¹æ¯”è¯„åˆ†ï¼Œç¡®ä¿æ ‡å‡†ä¸€è‡´"""
        # æ„å»ºå¯¹æ¯”æç¤ºè¯
        comparison_prompt = f"""{base_prompt}

## è¯„åˆ†è¯´æ˜
ä»¥ä¸‹æ˜¯{len(essays)}ç¯‡éœ€è¦è¯„åˆ†çš„ä½œæ–‡ã€‚è¯·å…ˆé˜…è¯»æ‰€æœ‰ä½œæ–‡ï¼Œç„¶åè¿›è¡Œç»Ÿä¸€æ ‡å‡†çš„è¯„åˆ†ã€‚

### ä½œæ–‡æ‘˜è¦åˆ—è¡¨ï¼š
"""

        for i, (summary, essay) in enumerate(zip(summaries, essays)):
            comparison_prompt += f"""
{i+1}. ä½œæ–‡ID: {essay.get('id')}
   æ ‡é¢˜: {essay.get('title', 'æ— ')}
   æ‘˜è¦: {summary['summary']}
   åŸæ–‡ç‰‡æ®µ: {essay.get('content', '')[:500]}...
"""

        comparison_prompt += """
è¯·å¯¹æ¯ç¯‡ä½œæ–‡è¿›è¡Œè¯„åˆ†ï¼Œå¹¶ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{
    "scores": [
        {
            "essay_id": "ä½œæ–‡1çš„ID",
            "total_score": 85,
            "grade": "ä¼˜ç§€",
            "dimensions": {...},
            "strengths": [...],
            "weaknesses": [...],
            "suggestions": [...]
        },
        ...
    ],
    "scoring_notes": "è¯„åˆ†è¯´æ˜"
}
```
"""

        result = await self._call_llm(comparison_prompt)
        return self._parse_scores(result, essays)

    async def _verify_extreme_scores(
        self,
        scores: List[Dict],
        essays: List[Dict],
        grade: str,
        essay_type: str
    ) -> List[Dict[str, Any]]:
        """äºŒæ¬¡éªŒè¯æç«¯åˆ†æ•°ï¼ˆæœ€é«˜åˆ†å’Œæœ€ä½åˆ†ï¼‰"""
        # æ‰¾å‡ºæœ€é«˜åˆ†å’Œæœ€ä½åˆ†çš„ä½œæ–‡
        if not scores:
            return scores

        sorted_scores = sorted(scores, key=lambda x: x.get("total_score", 0), reverse=True)

        # éªŒè¯å‰3åå’Œå3å
        verify_indices = set()
        for i in range(min(3, len(sorted_scores))):
            verify_indices.add(i)
        for i in range(max(0, len(sorted_scores) - 3), len(sorted_scores)):
            verify_indices.add(i)

        # é‡æ–°éªŒè¯
        for idx in verify_indices:
            score_entry = sorted_scores[idx]
            essay = next((e for e in essays if e.get("id") == score_entry.get("essay_id")), None)

            if essay:
                verification = await self._verify_single_essay(
                    essay, grade, essay_type, score_entry
                )
                # æ›´æ–°åˆ†æ•°
                for i, s in enumerate(scores):
                    if s.get("essay_id") == score_entry.get("essay_id"):
                        scores[i] = verification
                        break

        return scores

    async def _verify_single_essay(
        self,
        essay: Dict,
        grade: str,
        essay_type: str,
        original_score: Dict
    ) -> Dict[str, Any]:
        """å•ç¯‡ä½œæ–‡éªŒè¯"""
        verify_prompt = f"""è¯·é‡æ–°è¯„ä¼°ä»¥ä¸‹ä½œæ–‡çš„åˆ†æ•°ï¼š

å¹´çº§ï¼š{grade}
ç±»å‹ï¼š{essay_type}
æ ‡é¢˜ï¼š{essay.get('title', 'æ— ')}

å†…å®¹ï¼š
{essay.get('content', '')}

åŸå§‹è¯„åˆ†ï¼š
- æ€»åˆ†ï¼š{original_score.get('total_score', 0)}
- è¯„çº§ï¼š{original_score.get('grade', 'æœªçŸ¥')}
- å„ç»´åº¦å¾—åˆ†ï¼š{json.dumps(original_score.get('dimensions', {}), ensure_ascii=False)}

è¯·ç¡®è®¤æˆ–ä¿®æ­£è¯„åˆ†ï¼Œç¡®ä¿è¯„åˆ†ä¸å…¶ä»–ä½œæ–‡æ ‡å‡†ä¸€è‡´ã€‚
"""
        result = await self._call_llm(verify_prompt)
        verified = self._parse_single_score(result)
        return {
            **verified,
            "essay_id": essay.get("id"),
            "verified": True,
            "original_score": original_score.get("total_score")
        }

    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLM"""
        response = await self.llm_provider.generate(
            prompt=prompt,
            temperature=0.3,
            max_tokens=8192
        )
        return response.content

    def _parse_scores(self, response: str, essays: List[Dict]) -> List[Dict[str, Any]]:
        """è§£æè¯„åˆ†ç»“æœ"""
        try:
            # æå–JSON
            json_match = None
            for pattern in [r'```json\s*([\s\S]*?)\s*```', r'\{[\s\S]*"scores"[\s\S]*\}']:
                json_match = re.search(pattern, response)
                if json_match:
                    break

            if json_match:
                data = json.loads(json_match.group(1) if '```' in response else response)
                scores = data.get("scores", [])
            else:
                scores = []

            # æ˜ å°„å›åŸå§‹ä½œæ–‡
            result_map = {s.get("essay_id"): s for s in scores}

            # ç¡®ä¿æ‰€æœ‰ä½œæ–‡éƒ½æœ‰åˆ†æ•°
            for essay in essays:
                essay_id = essay.get("id")
                if essay_id not in result_map:
                    # æ²¡æœ‰åˆ†æ•°çš„ä½œæ–‡è®¾ä¸º0
                    result_map[essay_id] = {
                        "essay_id": essay_id,
                        "total_score": 0,
                        "grade": "å¾…æé«˜",
                        "dimensions": {},
                        "strengths": [],
                        "weaknesses": [],
                        "suggestions": ["è¯„åˆ†å¤±è´¥ï¼Œè¯·é‡è¯•"]
                    }

            return list(result_map.values())

        except Exception as e:
            # è§£æå¤±è´¥ï¼Œè¿”å›é”™è¯¯æ ‡è®°
            return [{
                "essay_id": essay.get("id"),
                "total_score": 0,
                "grade": "è¯„åˆ†é”™è¯¯",
                "error": str(e)
            } for essay in essays]

    def _parse_single_score(self, response: str) -> Dict[str, Any]:
        """è§£æå•ç¯‡ä½œæ–‡åˆ†æ•°"""
        # ç±»ä¼¼ _parse_scoresï¼Œä½†åªè¿”å›å•ç¯‡
        json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
        if json_match:
            data = json.loads(json_match.group(1))
            return data.get("score", {})
        return {}
```

## 11. æ‰¹é‡ä»»åŠ¡ç®¡ç†

```python
# app/services/batch/task_manager.py
from enum import Enum
from typing import Optional
from datetime import datetime
from dataclasses import dataclass, field
from pydantic import BaseModel


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    PARTIAL_FAILED = "partial_failed"
    FAILED = "failed"


class BatchTask(BaseModel):
    """æ‰¹é‡ä»»åŠ¡"""
    id: str
    user_id: str
    name: str
    grade: str
    essay_type: Optional[str] = None
    status: TaskStatus = TaskStatus.PENDING
    total_essays: int = 0
    processed_essays: int = 0
    failed_essays: int = 0
    progress: float = 0.0
    award_config: Optional[dict] = None
    created_at: datetime = field(default_factory=datetime.utcnow)
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None
    result_summary: Optional[dict] = None


class BatchTaskManager:
    """æ‰¹é‡ä»»åŠ¡ç®¡ç†å™¨"""

    def __init__(self, db_session):
        self.db = db_session

    async def create_task(
        self,
        user_id: str,
        name: str,
        grade: str,
        essay_type: Optional[str] = None,
        award_config: Optional[dict] = None
    ) -> BatchTask:
        """åˆ›å»ºæ‰¹é‡ä»»åŠ¡"""
        task = BatchTask(
            id=self._generate_task_id(),
            user_id=user_id,
            name=name,
            grade=grade,
            essay_type=essay_type,
            award_config=award_config
        )
        await self._save_task(task)
        return task

    async def update_progress(
        self,
        task_id: str,
        processed: int,
        failed: int = 0,
        total: Optional[int] = None
    ) -> None:
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        task = await self._get_task(task_id)
        task.processed_essays = processed
        task.failed_essays = failed

        if total:
            task.total_essays = total

        task.progress = (processed + failed) / task.total_essays * 100

        if task.progress >= 100:
            task.status = TaskStatus.COMPLETED
            task.completed_at = datetime.utcnow()

        await self._save_task(task)

    async def complete_task(
        self,
        task_id: str,
        result_summary: dict
    ) -> None:
        """å®Œæˆä»»åŠ¡"""
        task = await self._get_task(task_id)
        task.status = TaskStatus.COMPLETED
        task.completed_at = datetime.utcnow()
        task.progress = 100.0
        task.result_summary = result_summary
        await self._save_task(task)

    def _generate_task_id(self) -> str:
        """ç”Ÿæˆä»»åŠ¡ID"""
        import uuid
        return f"batch_{uuid.uuid4().hex[:12]}"

    async def _save_task(self, task: BatchTask) -> None:
        """ä¿å­˜ä»»åŠ¡åˆ°æ•°æ®åº“"""
        # å®ç°ä¿å­˜é€»è¾‘
        pass

    async def _get_task(self, task_id: str) -> BatchTask:
        """è·å–ä»»åŠ¡"""
        # å®ç°è·å–é€»è¾‘
        pass
```

## 12. è¯ä¹¦ç”Ÿæˆ

```python
# app/services/certificate/generator.py
from dataclasses import dataclass
from typing import Optional
from pathlib import Path
from datetime import datetime


@dataclass
class CertificateData:
    """è¯ä¹¦æ•°æ®"""
    student_name: str
    award_name: str
    essay_title: str
    score: float
    award_date: datetime
    awarding_unit: str = "é’å°‘å¹´å†™ä½œå¤§èµ›ç»„å§”ä¼š"
    certificate_id: str = ""
    custom_message: Optional[str] = None


class CertificateGenerator:
    """è¯ä¹¦ç”Ÿæˆå™¨"""

    TEMPLATES = {
        "formal": {
            "name": "æ­£å¼è¯ä¹¦",
            "background": "formal_bg.jpg",
            "border_color": "#C9A227",
            "font": "NotoSerifSC"
        },
        "encouragement": {
            "name": "é¼“åŠ±è¯ä¹¦",
            "background": "encourage_bg.jpg",
            "border_color": "#4A90D9",
            "font": "NotoSansSC"
        },
        "progress": {
            "name": "è¿›æ­¥è¯ä¹¦",
            "background": "progress_bg.jpg",
            "border_color": "#50C878",
            "font": "NotoSansSC"
        }
    }

    async def generate_certificate(
        self,
        data: CertificateData,
        template: str = "formal"
    ) -> bytes:
        """ç”Ÿæˆè¯ä¹¦å›¾ç‰‡"""
        template_config = self.TEMPLATES.get(template, self.TEMPLATES["formal"])

        # ä½¿ç”¨æŠ¥å‘Šç”Ÿæˆåº“ï¼ˆå¦‚ weasyprintã€reportlabï¼‰
        from reportlab.pdfgen import canvas
        from reportlab.lib.pagesizes import A4 Landscape
        from reportlab.lib.colors import HexColor

        buffer = buffer or io.BytesIO()
        c = canvas.Canvas(buffer, pagesize=A4 Landscape)
        width, height = A4 Landscape

        # ç»˜åˆ¶èƒŒæ™¯
        self._draw_background(c, width, height, template_config)

        # ç»˜åˆ¶è¯ä¹¦å†…å®¹
        self._draw_content(c, width, height, data, template_config)

        # ç»˜åˆ¶é˜²ä¼ªéªŒè¯ç 
        self._draw_verification(c, width, height, data)

        c.save()
        buffer.seek(0)
        return buffer.getvalue()

    def _draw_background(self, c, width, height, template):
        """ç»˜åˆ¶èƒŒæ™¯"""
        # ç»˜åˆ¶è¾¹æ¡†
        c.setStrokeColor(HexColor(template["border_color"]))
        c.setLineWidth(5)
        c.rect(30, 30, width - 60, height - 60)

        # å†…è¾¹æ¡†
        c.setLineWidth(2)
        c.rect(45, 45, width - 90, height - 90)

    def _draw_content(self, c, width, height, data: CertificateData, template):
        """ç»˜åˆ¶è¯ä¹¦å†…å®¹"""
        c.setFont("NotoSerifSC-Bold", 36)
        c.drawCentredString(width / 2, height - 120, "è£èª‰è¯ä¹¦")

        c.setFont("NotoSerifSC-Regular", 18)
        c.drawCentredString(width / 2, height - 180, f'å…¹è¯æ˜{data.student_name}åŒå­¦')

        c.drawCentredString(width / 2, height - 220, f'åœ¨"{data.essay_title}"ä½œæ–‡è¯„é€‰ä¸­')

        # å¥–é¡¹åç§°ï¼ˆçªå‡ºæ˜¾ç¤ºï¼‰
        c.setFont("NotoSerifSC-Bold", 32)
        c.setFillColor(HexColor(template["border_color"]))
        c.drawCentredString(width / 2, height - 300, f'è£è·{data.award_name}')
        c.setFillColor(HexColor("#000000"))

        c.setFont("NotoSerifSC-Regular", 14)
        c.drawCentredString(width / 2, height - 360, f'è¯„åˆ†ï¼š{data.score}åˆ†')

        # è½æ¬¾
        c.setFont("NotoSerifSC-Regular", 14)
        c.drawCentredString(width / 2, height - 420, data.awarding_unit)

        # æ—¥æœŸ
        date_str = data.award_date.strftime("%Yå¹´%mæœˆ%dæ—¥")
        c.drawCentredString(width / 2, height - 450, date_str)

    def _draw_verification(self, c, width, height, data: CertificateData):
        """ç»˜åˆ¶é˜²ä¼ªéªŒè¯ç """
        c.setFont("NotoSansSC-Regular", 10)
        c.setFillColor(HexColor("#999999"))
        c.drawString(60, 60, f"è¯ä¹¦ç¼–å·ï¼š{data.certificate_id}")
        c.drawString(width - 200, 60, f"éªŒè¯ç ï¼š{data.certificate_id[-8:]}")

    async def generate_batch_certificates(
        self,
        winners: list,
        template: str = "formal"
    ) -> dict:
        """æ‰¹é‡ç”Ÿæˆè¯ä¹¦"""
        results = {}
        for winner in winners:
            data = CertificateData(
                student_name=winner["student_name"],
                award_name=winner["award"],
                essay_title=winner["title"],
                score=winner["score"],
                award_date=datetime.utcnow(),
                certificate_id=self._generate_cert_id(winner)
            )
            pdf_content = await self.generate_certificate(data, template)
            results[winner["essay_id"]] = pdf_content

        return results

    def _generate_cert_id(self, winner: dict) -> str:
        """ç”Ÿæˆè¯ä¹¦ç¼–å·"""
        import hashlib
        timestamp = datetime.utcnow().strftime("%Y%m%d%H%M%S")
        raw = f"{winner['essay_id']}{timestamp}"
        return f"CERT-{hashlib.md5(raw.encode()).hexdigest()[:8].upper()}"
```

## 13. æ­£ç¡®æ€§çº¦æŸä¸ä¸å˜é‡

### 13.1 è¯„åˆ†æ­£ç¡®æ€§

- æ€»åˆ†å¿…é¡»ç­‰äºå„ç»´åº¦å¾—åˆ†ä¹‹å’Œï¼ˆè¯¯å·®ä¸è¶…è¿‡2åˆ†ï¼‰
- å„ç»´åº¦å¾—åˆ†å¿…é¡»åœ¨ 0 åˆ°æ»¡åˆ†ä¹‹é—´
- è¯„çº§å¿…é¡»ä¸æ€»åˆ†åŒ¹é…ï¼ˆä¼˜ç§€: 85-100, è‰¯å¥½: 70-84, åˆæ ¼: 60-69, å¾…æé«˜: 0-59ï¼‰
- LLM å“åº”å¿…é¡»ä¸ºæœ‰æ•ˆçš„ JSON æ ¼å¼

### 13.2 å¥–é¡¹çº¦æŸæ­£ç¡®æ€§

- ä¸€ç­‰å¥– N1 åï¼šç¬¬1ååˆ†æ•°ä¸º Xï¼Œåˆ™å…¶ä»–ä½œæ–‡åˆ†æ•°å¿…é¡» < X
- äºŒç­‰å¥– N2 åï¼šç¬¬(N1+1)åˆ°(N1+N2)åçš„æœ€ä½åˆ†æ•°ä¸º Yï¼Œåˆ™å…¶ä»–ä½œæ–‡åˆ†æ•°å¿…é¡» < Y
- ä¸‰ç­‰å¥– N3 åï¼šç¬¬(N1+N2+1)åˆ°(N1+N2+N3)åçš„æœ€ä½åˆ†æ•°ä¸º Zï¼Œåˆ™å…¶ä»–ä½œæ–‡åˆ†æ•°å¿…é¡» < Z
- åŒåˆ†ä½œæ–‡å¹¶åˆ—è·å¥–ï¼Œè‡ªåŠ¨è°ƒæ•´å¥–é¡¹æ•°é‡

### 13.3 æ–‡ä»¶å¤„ç†æ­£ç¡®æ€§

- ZIPæ–‡ä»¶è§£å‹åå¿…é¡»ç«‹å³åˆ é™¤åŸå§‹å‹ç¼©åŒ…
- ä¸Šä¼ æ–‡ä»¶å¿…é¡»éªŒè¯ç±»å‹å’Œå¤§å°
- æ–‡ä»¶å¤„ç†å¤±è´¥å¿…é¡»è¿”å›è¯¦ç»†é”™è¯¯ä¿¡æ¯

### 13.4 æ•°æ®å®Œæ•´æ€§

- æ¯ç¯‡ä½œæ–‡å¿…é¡»å…³è”ä¸€ä¸ªç”¨æˆ·
- æ¯ç¯‡ä½œæ–‡æœ€å¤šæœ‰ä¸€ä¸ªè§£æç»“æœ
- æ¯ç¯‡ä½œæ–‡å¯ä»¥æœ‰å¤šæ¬¡è¯„æµ‹è®°å½•
- æ¨¡å‹é…ç½®å¿…é¡»å…³è”ä¸€ä¸ªç”¨æˆ·

### 13.5 å¹¶å‘æ§åˆ¶

- åŒä¸€ç”¨æˆ·åŒæ—¶åªèƒ½å‘èµ·ä¸€æ¬¡è¯„æµ‹è¯·æ±‚
- ä½œæ–‡åˆ é™¤æ—¶çº§è”åˆ é™¤å…³è”çš„è¯„æµ‹å’Œè§£æç»“æœ
- æ¨¡å‹é…ç½®æ›´æ–°æ—¶éœ€è¦éªŒè¯ API Key æœ‰æ•ˆæ€§
- æ‰¹é‡ä»»åŠ¡å¤„ç†æ”¯æŒä¸­æ–­å’Œæ¢å¤

## 5. æ•°æ®æ¨¡å‹è®¾è®¡

### 5.1 å®ä½“å…³ç³»å›¾

```mermaid
erDiagram
    User ||--o{ Essay : writes
    User ||--o{ ModelConfig : configures
    User ||--o{ EssayEvaluation : receives
    
    Essay ||--o{ EssayEvaluation : has
    Essay ||--|| EssayParserResult : analyzed_by
    
    ModelConfig ||--o{ ProviderConfig : uses
    
    Essay {
        uuid id PK
        uuid user_id FK
        string title
        text content
        string grade
        string essay_type
        string status
        datetime created_at
    }
    
    EssayEvaluation {
        uuid id PK
        uuid essay_id FK
        int total_score
        string grade
        json dimension_scores
        json strengths
        json weaknesses
        json suggestions
        json essay_type_analysis
        string model_provider
        string model_name
        datetime created_at
    }
    
    EssayParserResult {
        uuid id PK
        uuid essay_id FK
        int total_characters
        int words_without_punctuation
        int sentence_count
        int paragraph_count
        float avg_sentence_length
        json vocabulary_richness
        json potential_typos
        json punctuation_usage
    }
    
    User {
        uuid id PK
        string email
        string hashed_password
        string name
        string avatar
        boolean is_active
        datetime created_at
    }
    
    ModelConfig {
        uuid id PK
        uuid user_id FK
        string provider
        string provider_name
        string api_key
        json config
        boolean is_default
        datetime created_at
    }
    
    ExampleEssay {
        uuid id PK
        string title
        text content
        string grade
        string essay_type
        string score_range
        json analysis
    }
```

### 5.2 æ•°æ®åº“è¡¨å®šä¹‰

```python
# app/models/domain/essay.py
from sqlalchemy import Column, String, Text, Integer, Float, ForeignKey, DateTime, JSON, Boolean
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
from datetime import datetime
import uuid

from app.models.database import Base


class Essay(Base):
    """ä½œæ–‡æ¨¡å‹"""
    __tablename__ = "essays"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=False)
    title = Column(String(200), nullable=True)
    content = Column(Text, nullable=False)
    grade = Column(String(20), nullable=False)  # ä¸€å¹´çº§è‡³å…­å¹´çº§
    essay_type = Column(String(50), nullable=True)  # è®°å™æ–‡ã€è®®è®ºæ–‡ç­‰
    status = Column(String(20), default="pending")  # pending, evaluating, completed, failed
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # å…³ç³»
    user = relationship("User", back_populates="essays")
    evaluations = relationship("EssayEvaluation", back_populates="essay", cascade="all, delete-orphan")
    parser_result = relationship("EssayParserResult", back_populates="essay", uselist=False)


class EssayEvaluation(Base):
    """ä½œæ–‡è¯„æµ‹ç»“æœæ¨¡å‹"""
    __tablename__ = "essay_evaluations"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    essay_id = Column(UUID(as_uuid=True), ForeignKey("essays.id"), nullable=False)
    
    total_score = Column(Integer, nullable=False)
    grade = Column(String(20), nullable=False)  # ä¼˜ç§€ã€è‰¯å¥½ã€åˆæ ¼ã€å¾…æé«˜
    
    dimension_scores = Column(JSON, nullable=False)  # å„ç»´åº¦å¾—åˆ†è¯¦æƒ…
    strengths = Column(JSON, nullable=False)  # ä¼˜ç‚¹åˆ—è¡¨
    weaknesses = Column(JSON, nullable=False)  # ä¸è¶³åˆ—è¡¨
    suggestions = Column(JSON, nullable=False)  # æ”¹è¿›å»ºè®®
    
    essay_type_analysis = Column(JSON, nullable=True)  # å†™ä½œç±»å‹åˆ†æ
    
    model_provider = Column(String(50), nullable=False)  # æ¨¡å‹æœåŠ¡å•†
    model_name = Column(String(100), nullable=False)  # æ¨¡å‹åç§°
    prompt_tokens = Column(Integer, nullable=True)
    completion_tokens = Column(Integer, nullable=True)
    
    created_at = Column(DateTime, default=datetime.utcnow)

    # å…³ç³»
    essay = relationship("Essay", back_populates="evaluations")


class EssayParserResult(Base):
    """ä½œæ–‡è§£æç»“æœæ¨¡å‹"""
    __tablename__ = "essay_parser_results"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    essay_id = Column(UUID(as_uuid=True), ForeignKey("essays.id"), nullable=False, unique=True)
    
    total_characters = Column(Integer, nullable=False)
    words_without_punctuation = Column(Integer, nullable=False)
    sentence_count = Column(Integer, nullable=False)
    paragraph_count = Column(Integer, nullable=False)
    avg_sentence_length = Column(Float, nullable=True)
    
    vocabulary_richness = Column(JSON, nullable=True)
    potential_typos = Column(JSON, nullable=True)
    punctuation_usage = Column(JSON, nullable=True)

    # å…³ç³»
    essay = relationship("Essay", back_populates="parser_result")


class ModelConfig(Base):
    """æ¨¡å‹é…ç½®æ¨¡å‹"""
    __tablename__ = "model_configs"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=False)
    
    provider = Column(String(50), nullable=False)  # openai, anthropic, google ç­‰
    provider_name = Column(String(100), nullable=False)  # æ˜¾ç¤ºåç§°
    api_key = Column(Text, nullable=False)  # åŠ å¯†å­˜å‚¨
    config = Column(JSON, nullable=True)  # é¢å¤–é…ç½®
    
    is_default = Column(Boolean, default=False)
    is_active = Column(Boolean, default=True)
    
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


class ExampleEssay(Base):
    """èŒƒæ–‡æ¨¡å‹"""
    __tablename__ = "example_essays"

    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    
    title = Column(String(200), nullable=False)
    content = Column(Text, nullable=False)
    grade = Column(String(20), nullable=False)
    essay_type = Column(String(50), nullable=False)
    score_range = Column(String(20), nullable=False)  # 85-100, 70-84, 60-69
    
    analysis = Column(JSON, nullable=True)  # èŒƒæ–‡åˆ†æ
    
    created_at = Column(DateTime, default=datetime.utcnow)
```

## 6. API æ¥å£è®¾è®¡

### 6.1 API è·¯ç”±ç»“æ„

```
/api/v1/
â”œâ”€â”€ /auth/
â”‚   â”œâ”€â”€ POST /register          # ç”¨æˆ·æ³¨å†Œ
â”‚   â”œâ”€â”€ POST /login             # ç”¨æˆ·ç™»å½•
â”‚   â”œâ”€â”€ POST /refresh           # åˆ·æ–°ä»¤ç‰Œ
â”‚   â””â”€â”€ GET /me                 # è·å–å½“å‰ç”¨æˆ·
â”‚
â”œâ”€â”€ /essays/
â”‚   â”œâ”€â”€ POST /                  # åˆ›å»ºä½œæ–‡
â”‚   â”œâ”€â”€ GET /                    # åˆ—å‡ºä½œæ–‡
â”‚   â”œâ”€â”€ GET /{id}               # è·å–ä½œæ–‡è¯¦æƒ…
â”‚   â”œâ”€â”€ DELETE /{id}            # åˆ é™¤ä½œæ–‡
â”‚   â””â”€â”€ POST /{id}/evaluate     # æäº¤è¯„æµ‹
â”‚
â”œâ”€â”€ /evaluations/
â”‚   â”œâ”€â”€ GET /essay/{essay_id}   # è·å–è¯„æµ‹ç»“æœ
â”‚   â”œâ”€â”€ GET /history            # è·å–è¯„æµ‹å†å²
â”‚   â””â”€â”€ GET /statistics         # è·å–ç»Ÿè®¡æ•°æ®
â”‚
â”œâ”€â”€ /examples/
â”‚   â”œâ”€â”€ GET /                    # åˆ—å‡ºèŒƒæ–‡
â”‚   â”œâ”€â”€ GET /{id}                # è·å–èŒƒæ–‡è¯¦æƒ…
â”‚   â””â”€â”€ GET /recommend           # æ¨èèŒƒæ–‡
â”‚
â”œâ”€â”€ /models/
â”‚   â”œâ”€â”€ GET /providers           # åˆ—å‡ºå¯ç”¨æ¨¡å‹å•†
â”‚   â”œâ”€â”€ GET /configs            # åˆ—å‡ºç”¨æˆ·æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ POST /configs           # æ·»åŠ æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ PUT /configs/{id}       # æ›´æ–°æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ DELETE /configs/{id}    # åˆ é™¤æ¨¡å‹é…ç½®
â”‚   â””â”€â”€ POST /configs/{id}/test # æµ‹è¯•æ¨¡å‹é…ç½®
â”‚
â””â”€â”€ /users/
    â”œâ”€â”€ PUT /profile             # æ›´æ–°ä¸ªäººèµ„æ–™
    â”œâ”€â”€ PUT /password            # ä¿®æ”¹å¯†ç 
    â””â”€â”€ DELETE /                  # åˆ é™¤è´¦æˆ·
```

### 6.2 æ ¸å¿ƒæ¥å£å®šä¹‰

```python
# app/api/v1/endpoints/essays.py
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Optional, List

from app.api.deps import get_current_user, get_db
from app.schemas.essay import EssayCreate, EssayResponse, EssayEvaluateResponse
from app.services.essay.service import EssayService
from app.services.scoring.engine import EssayScoringEngine
from app.services.llm.factory import LLMFactory

router = APIRouter()


@router.post("/", response_model=EssayResponse)
async def create_essay(
    essay_in: EssayCreate,
    current_user = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """åˆ›å»ºæ–°ä½œæ–‡"""
    essay = await EssayService.create(db, essay_in, current_user.id)
    return essay


@router.post("/{essay_id}/evaluate", response_model=EssayEvaluateResponse)
async def evaluate_essay(
    essay_id: str,
    model_config_id: Optional[str] = None,
    current_user = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """è¯„æµ‹ä½œæ–‡"""
    # 1. è·å–ä½œæ–‡
    essay = await EssayService.get_by_id(db, essay_id, current_user.id)
    if not essay:
        raise HTTPException(status_code=404, detail="ä½œæ–‡ä¸å­˜åœ¨")

    # 2. è·å–æ¨¡å‹é…ç½®
    if model_config_id:
        config = await ModelConfigService.get_by_id(db, model_config_id, current_user.id)
    else:
        config = await ModelConfigService.get_default(db, current_user.id)

    if not config:
        raise HTTPException(status_code=400, detail="è¯·å…ˆé…ç½®è¯„åˆ†æ¨¡å‹")

    # 3. è·å– LLM Provider
    llm_provider = LLMFactory.get_provider(
        config.provider,
        api_key=config.api_key
    )

    # 4. æ‰§è¡Œè¯„åˆ†
    scoring_engine = EssayScoringEngine(llm_provider)
    result = await scoring_engine.score_essay(
        essay_content=essay.content,
        essay_title=essay.title,
        grade=essay.grade,
        essay_type=essay.essay_type
    )

    # 5. ä¿å­˜è¯„æµ‹ç»“æœ
    evaluation = await EssayService.save_evaluation(db, essay.id, result, config)

    return {
        "essay": essay,
        "evaluation": evaluation,
        "parser_result": essay.parser_result
    }


@router.get("/history")
async def get_history(
    grade: Optional[str] = None,
    essay_type: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    page: int = 1,
    page_size: int = 10,
    current_user = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """è·å–è¯„æµ‹å†å²"""
    return await EssayService.get_history(
        db, current_user.id, grade, essay_type, start_date, end_date, page, page_size
    )
```

## 7. æ­£ç¡®æ€§çº¦æŸä¸ä¸å˜é‡

### 7.1 è¯„åˆ†æ­£ç¡®æ€§

- æ€»åˆ†å¿…é¡»ç­‰äºå„ç»´åº¦å¾—åˆ†ä¹‹å’Œï¼ˆè¯¯å·®ä¸è¶…è¿‡2åˆ†ï¼‰
- å„ç»´åº¦å¾—åˆ†å¿…é¡»åœ¨ 0 åˆ°æ»¡åˆ†ä¹‹é—´
- è¯„çº§å¿…é¡»ä¸æ€»åˆ†åŒ¹é…ï¼ˆä¼˜ç§€: 85-100, è‰¯å¥½: 70-84, åˆæ ¼: 60-69, å¾…æé«˜: 0-59ï¼‰
- LLM å“åº”å¿…é¡»ä¸ºæœ‰æ•ˆçš„ JSON æ ¼å¼

### 7.2 æ•°æ®å®Œæ•´æ€§

- æ¯ç¯‡ä½œæ–‡å¿…é¡»å…³è”ä¸€ä¸ªç”¨æˆ·
- æ¯ç¯‡ä½œæ–‡æœ€å¤šæœ‰ä¸€ä¸ªè§£æç»“æœ
- æ¯ç¯‡ä½œæ–‡å¯ä»¥æœ‰å¤šæ¬¡è¯„æµ‹è®°å½•
- æ¨¡å‹é…ç½®å¿…é¡»å…³è”ä¸€ä¸ªç”¨æˆ·

### 7.3 å¹¶å‘æ§åˆ¶

- åŒä¸€ç”¨æˆ·åŒæ—¶åªèƒ½å‘èµ·ä¸€æ¬¡è¯„æµ‹è¯·æ±‚
- ä½œæ–‡åˆ é™¤æ—¶çº§è”åˆ é™¤å…³è”çš„è¯„æµ‹å’Œè§£æç»“æœ
- æ¨¡å‹é…ç½®æ›´æ–°æ—¶éœ€è¦éªŒè¯ API Key æœ‰æ•ˆæ€§

## 8. é”™è¯¯å¤„ç†ç­–ç•¥

| é”™è¯¯ç±»å‹ | HTTP çŠ¶æ€ç  | å¤„ç†ç­–ç•¥ |
|----------|-------------|----------|
| è®¤è¯å¤±è´¥ | 401 | è¿”å›ç™»å½•æç¤ºï¼Œå¼•å¯¼ç”¨æˆ·ç™»å½• |
| æƒé™ä¸è¶³ | 403 | æç¤ºæƒé™ä¸è¶³ |
| èµ„æºä¸å­˜åœ¨ | 404 | æ˜¾ç¤ºèµ„æºä¸å­˜åœ¨æç¤º |
| éªŒè¯å¤±è´¥ | 422 | è¿”å›å…·ä½“éªŒè¯é”™è¯¯ä¿¡æ¯ |
| API Key æ— æ•ˆ | 400 | æç¤ºæ£€æŸ¥ API Key é…ç½® |
| LLM è°ƒç”¨å¤±è´¥ | 502 | æ˜¾ç¤ºæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œå»ºè®®é‡è¯• |
| é™æµ | 429 | æ˜¾ç¤ºç¨åå†è¯•æç¤º |
| æœåŠ¡å™¨é”™è¯¯ | 500 | æ˜¾ç¤ºç³»ç»Ÿé”™è¯¯æ—¥å¿— |

## 9. æµ‹è¯•ç­–ç•¥

### 9.1 æµ‹è¯•è¦†ç›–

| æµ‹è¯•ç±»å‹ | è¦†ç›–èŒƒå›´ | å·¥å…· |
|----------|----------|------|
| å•å…ƒæµ‹è¯• | LLM Providerã€Parserã€Formatter | pytest |
| é›†æˆæµ‹è¯• | API æ¥å£ã€æ•°æ®åº“æ“ä½œ | pytest + TestClient |
| E2E æµ‹è¯• | å®Œæ•´ç”¨æˆ·æµç¨‹ | Playwright |
| å¾€è¿”éªŒè¯ | Parser è§£æå‡†ç¡®æ€§ | å•å…ƒæµ‹è¯• |

### 9.2 æµ‹è¯•ç”¨ä¾‹ç¤ºä¾‹

```python
# tests/test_parser.py
from app.services.scoring.parser import EssayParser

def test_parse_basic_essay():
    parser = EssayParser()
    content = "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œæˆ‘å’Œå¦ˆå¦ˆä¸€èµ·å»å…¬å›­ç©ã€‚"
    
    result = parser.parse(content)
    
    assert result["total_characters"] == len("ä»Šå¤©å¤©æ°”å¾ˆå¥½æˆ‘å’Œå¦ˆå¦ˆä¸€èµ·å»å…¬å›­ç©")
    assert result["sentence_count"] == 1
    assert result["paragraph_count"] == 1

def test_roundtrip_validation():
    parser = EssayParser()
    original = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­ã€‚"
    
    parsed = parser.parse(original)
    
    assert parser.roundtrip_validation(original, parsed) == True
```

## 10. éƒ¨ç½²æ¶æ„

```mermaid
graph TB
    subgraph ç”¨æˆ·è®¿é—®
        Browser[æµè§ˆå™¨]
        Mobile[ç§»åŠ¨è®¾å¤‡]
    end

    subgraph CDN
        Cloudflare[Cloudflare CDN]
    end

    subgraph Verceléƒ¨ç½²
        NextJS[Next.js å‰ç«¯]
    end

    subgraph AWSéƒ¨ç½²
        subgraph åº”ç”¨å±‚
            FastAPI[FastAPI åç«¯ x 3]
            Celery[Celery Worker x 2]
        end
        
        subgraph æ•°æ®å±‚
            Postgres[(PostgreSQL ä¸»ä»)]
            Redis[(Redis é›†ç¾¤)]
            S3[(S3 å…¼å®¹å­˜å‚¨)]
        end
        
        subgraph ç›‘æ§
            Prometheus[Prometheus]
            Grafana[Grafana]
        end
    end

    subgraph å¤–éƒ¨æœåŠ¡
        OpenAI[OpenAI API]
        Claude[Claude API]
        Gemini[Gemini API]
        Baidu[ç™¾åº¦æ–‡å¿ƒ]
        Aliyun[é˜¿é‡Œé€šä¹‰]
        ZhiPu[æ™ºè°±æ¸…è¨€]
    end

    Browser --> Cloudflare
    Mobile --> Cloudflare
    Cloudflare --> Vercel
    Vercel --> NextJS
    Cloudflare --> AWS
    AWS --> FastAPI
    FastAPI --> Postgres
    FastAPI --> Redis
    FastAPI --> S3
    FastAPI --> Celery
    FastAPI --> OpenAI
    FastAPI --> Claude
    FastAPI --> Gemini
    FastAPI --> Baidu
    FastAPI --> Aliyun
    FastAPI --> ZhiPu
```

## 11. å‚è€ƒèµ„æ–™

[^1]: (shadcn/ui Documentation) - https://ui.shadcn.com
[^2]: (FastAPI Documentation) - https://fastapi.tiangolo.com
[^3]: (OpenAI API Documentation) - https://platform.openai.com/docs
[^4]: (Anthropic Claude Documentation) - https://docs.anthropic.com
[^5]: (Google Gemini Documentation) - https://ai.google.dev/docs
[^6]: (ç™¾åº¦æ–‡å¿ƒä¸€è¨€ API) - https://cloud.baidu.com/doc/WENXINWORKSHOP/index.html
[^7]: (é˜¿é‡Œäº‘é€šä¹‰åƒé—® API) - https://help.aliyun.com/zh/dashscope
[^8]: (æ™ºè°±æ¸…è¨€ API) - https://open.bigmodel.cn/dev/howuse/introduction
